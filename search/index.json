[{"content":"VGGFace是牛津大学视觉组于2015年发表，VGGNet也是他们提出的，是基于VGGNet的人脸识别模型。\n 文献 官网  为什么不能在pytorch上丝滑使用vggface 首先，vggface是基于vgg16架构的，pytorch本身也提供了vgg16等预训练模型（categories是imagenet_classes），见VGG-NETS。\n但是pytorch没有针对vggface数据集训练的vggface的预训练模型，你可以在官网的下载处看到提供的如下几种格式：\n vgg_face_matconvnet.tar.gz: Face detection and VGG Face descriptor source code and models (MatConvNet) vgg_face_torch.tar.gz: VGG Face descriptor source code and models (Torch) vgg_face_caffe.tar.gz: VGG Face descriptor source code and models (Caffe)  也许你会想，这不是有Torch格式的预训练模型吗？ 如果进行尝试，会发现是不行的。\n困难的真正原因是，之前的torch是使用lua语言，之后在2017年根据python重构了代码变成pytorch，而vgg-face的作者提供的是torch模型，而不是pytorch的模型。VGGface2是支持的（但vggface2数据集已经寄了），还是因为vggface有些年份了。\n实践 所以问题，出现了 ： pytorch 如何获得预训练模型 过去有\nfrom torch.utils.serialization import load_lua x = load_lua(\u0026#39;x.t7\u0026#39;) 但pytorch在1.0之后删除了torch.utils.serialization，目前可以通过torchfile.load读取，但会报错：\nTypeError: unhashable type: \u0026#39;numpy.ndarray\u0026#39; As of PyTorch 1.0 torch.utils.serialization is completely removed. Hence no one can import models from Lua Torch into PyTorch anymore. Instead, I would suggest installing PyTorch 0.4.1 through pip in a conda environment (so that you can remove it after this) and use this repo to convert your Lua Torch model to PyTorch model, not just the torch.nn.legacy model that you cannot use for training. Then use PyTorch 1.xx to do whatever with it. You can also train your converted Lua Torch models in PyTorch this way :) 来源\n但尝试失败，包括之后尝试的三个github的repo：PyVGGFace 、convert_torch_to_pytorch和 vgg-face.pytorch(issue中作者提到他仍能在linux中运行（今年8月))，希望转化成能用的形式，均因为相同的原因失败。\n发现网页Samuel Albanie,能下载网络框架的py文件，但不能下载含有权重信息的.pth文件（也可以不去下，底下完整代码里有这玩意）\n尝试使用GitHub上的caffemodel2pytorch(这玩意获得proto是通过request的，本地的prototxt文件读不进去)和Caffe2Pytorch(易用，但是0.4.1以上版本没有torch.legacy，而使用anaconda激活的虚拟环境中，pytorch0.4.1报错No module named “caffe”)\n依着上面提到的vgg-face.pytorch的issue的思路，使用自己电脑的Ubuntu子系统使用PyVGGFace，成功得到权重文件vggface.pth\n如何将权重载入到模型框架里？ 如果直接使用torch.load导入：\nmodel = torch.load(r\u0026#34;D:\\Dataset\\models\\vggface.pth\u0026#34;) model.eval() AttributeError: \u0026#39;collections.OrderedDict\u0026#39; object has no attribute \u0026#39;eval\u0026#39; 原因是这仅是字典形式的权重数据，没有模型的实体。想用来自Samuel Albanie的模型框架文件获得转化后的权重数据，报错如下，可以看出是字典的键值不匹配。\nRuntimeError: Error(s) in loading state_dict for Vgg_face_dag: Missing key(s) in state_dict: \u0026#34;conv_1_1.weight\u0026#34;, \u0026#34;conv_1_1.bias\u0026#34;, \u0026#34;conv1_2.weight\u0026#34;, \u0026#34;conv1_2.bias\u0026#34;, \u0026#34;conv2_1.weight\u0026#34;, \u0026#34;conv2_1.bias\u0026#34;, \u0026#34;conv2_2.weight\u0026#34;, \u0026#34;conv2_2.bias\u0026#34;, \u0026#34;conv3_1.weight\u0026#34;, \u0026#34;conv3_1.bias\u0026#34;, \u0026#34;conv3_2.weight\u0026#34;, \u0026#34;conv3_2.bias\u0026#34;, \u0026#34;conv3_3.weight\u0026#34;, \u0026#34;conv3_3.bias\u0026#34;, \u0026#34;conv4_1.weight\u0026#34;, \u0026#34;conv4_1.bias\u0026#34;, \u0026#34;conv4_2.weight\u0026#34;, \u0026#34;conv4_2.bias\u0026#34;, \u0026#34;conv4_3.weight\u0026#34;, \u0026#34;conv4_3.bias\u0026#34;, \u0026#34;conv5_1.weight\u0026#34;, \u0026#34;conv5_1.bias\u0026#34;, \u0026#34;conv5_2.weight\u0026#34;, \u0026#34;conv5_2.bias\u0026#34;, \u0026#34;conv5_3.weight\u0026#34;, \u0026#34;conv5_3.bias\u0026#34;, \u0026#34;fc6.weight\u0026#34;, \u0026#34;fc6.bias\u0026#34;, \u0026#34;fc7.weight\u0026#34;, \u0026#34;fc7.bias\u0026#34;, \u0026#34;fc8.weight\u0026#34;, \u0026#34;fc8.bias\u0026#34;. Unexpected key(s) in state_dict: \u0026#34;features.conv_1_1.weight\u0026#34;, \u0026#34;features.conv_1_1.bias\u0026#34;, \u0026#34;features.conv_1_2.weight\u0026#34;, \u0026#34;features.conv_1_2.bias\u0026#34;, \u0026#34;features.conv_2_1.weight\u0026#34;, \u0026#34;features.conv_2_1.bias\u0026#34;, \u0026#34;features.conv_2_2.weight\u0026#34;, \u0026#34;features.conv_2_2.bias\u0026#34;, \u0026#34;features.conv_3_1.weight\u0026#34;, \u0026#34;features.conv_3_1.bias\u0026#34;, \u0026#34;features.conv_3_2.weight\u0026#34;, \u0026#34;features.conv_3_2.bias\u0026#34;, \u0026#34;features.conv_3_3.weight\u0026#34;, \u0026#34;features.conv_3_3.bias\u0026#34;, \u0026#34;features.conv_4_1.weight\u0026#34;, \u0026#34;features.conv_4_1.bias\u0026#34;, \u0026#34;features.conv_4_2.weight\u0026#34;, \u0026#34;features.conv_4_2.bias\u0026#34;, \u0026#34;features.conv_4_3.weight\u0026#34;, \u0026#34;features.conv_4_3.bias\u0026#34;, \u0026#34;features.conv_5_1.weight\u0026#34;, \u0026#34;features.conv_5_1.bias\u0026#34;, \u0026#34;features.conv_5_2.weight\u0026#34;, \u0026#34;features.conv_5_2.bias\u0026#34;, \u0026#34;features.conv_5_3.weight\u0026#34;, \u0026#34;features.conv_5_3.bias\u0026#34;, \u0026#34;fc.fc6.weight\u0026#34;, \u0026#34;fc.fc6.bias\u0026#34;, \u0026#34;fc.fc7.weight\u0026#34;, \u0026#34;fc.fc7.bias\u0026#34;, \u0026#34;fc.fc8.weight\u0026#34;, \u0026#34;fc.fc8.bias\u0026#34;. 实测不能通过在定义层时在conv前添加features.xxx解决\nself.add_module(\u0026#34;features.conv_1_1\u0026#34;,nn.Conv2d(3, 64, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))) KeyError: \u0026#39;module name can\\\u0026#39;t contain \u0026#34;.\u0026#34;, got: features.conv_1_1\u0026#39; 写函数,得到新字典后成功获得完整模型实例\ndef transform_key(model): #列表来自报错内容，可复制进来更改，创建一个新字典，将key 从post_names -\u0026gt; names names = [\u0026#34;conv_1_1.weight\u0026#34;, \u0026#34;conv_1_1.bias\u0026#34;, \u0026#34;conv1_2.weight\u0026#34;, \u0026#34;conv1_2.bias\u0026#34;, \u0026#34;conv2_1.weight\u0026#34;, \u0026#34;conv2_1.bias\u0026#34;, \u0026#34;conv2_2.weight\u0026#34;, \u0026#34;conv2_2.bias\u0026#34;, \u0026#34;conv3_1.weight\u0026#34;, \u0026#34;conv3_1.bias\u0026#34;, \u0026#34;conv3_2.weight\u0026#34;, \u0026#34;conv3_2.bias\u0026#34;, \u0026#34;conv3_3.weight\u0026#34;, \u0026#34;conv3_3.bias\u0026#34;, \u0026#34;conv4_1.weight\u0026#34;, \u0026#34;conv4_1.bias\u0026#34;, \u0026#34;conv4_2.weight\u0026#34;, \u0026#34;conv4_2.bias\u0026#34;, \u0026#34;conv4_3.weight\u0026#34;, \u0026#34;conv4_3.bias\u0026#34;, \u0026#34;conv5_1.weight\u0026#34;, \u0026#34;conv5_1.bias\u0026#34;, \u0026#34;conv5_2.weight\u0026#34;, \u0026#34;conv5_2.bias\u0026#34;, \u0026#34;conv5_3.weight\u0026#34;, \u0026#34;conv5_3.bias\u0026#34;, \u0026#34;fc6.weight\u0026#34;, \u0026#34;fc6.bias\u0026#34;, \u0026#34;fc7.weight\u0026#34;, \u0026#34;fc7.bias\u0026#34;, \u0026#34;fc8.weight\u0026#34;, \u0026#34;fc8.bias\u0026#34;] post_names = [\u0026#34;features.conv_1_1.weight\u0026#34;, \u0026#34;features.conv_1_1.bias\u0026#34;, \u0026#34;features.conv_1_2.weight\u0026#34;, \u0026#34;features.conv_1_2.bias\u0026#34;, \u0026#34;features.conv_2_1.weight\u0026#34;, \u0026#34;features.conv_2_1.bias\u0026#34;, \u0026#34;features.conv_2_2.weight\u0026#34;, \u0026#34;features.conv_2_2.bias\u0026#34;, \u0026#34;features.conv_3_1.weight\u0026#34;, \u0026#34;features.conv_3_1.bias\u0026#34;, \u0026#34;features.conv_3_2.weight\u0026#34;, \u0026#34;features.conv_3_2.bias\u0026#34;, \u0026#34;features.conv_3_3.weight\u0026#34;, \u0026#34;features.conv_3_3.bias\u0026#34;, \u0026#34;features.conv_4_1.weight\u0026#34;, \u0026#34;features.conv_4_1.bias\u0026#34;, \u0026#34;features.conv_4_2.weight\u0026#34;, \u0026#34;features.conv_4_2.bias\u0026#34;, \u0026#34;features.conv_4_3.weight\u0026#34;, \u0026#34;features.conv_4_3.bias\u0026#34;, \u0026#34;features.conv_5_1.weight\u0026#34;, \u0026#34;features.conv_5_1.bias\u0026#34;, \u0026#34;features.conv_5_2.weight\u0026#34;, \u0026#34;features.conv_5_2.bias\u0026#34;, \u0026#34;features.conv_5_3.weight\u0026#34;, \u0026#34;features.conv_5_3.bias\u0026#34;, \u0026#34;fc.fc6.weight\u0026#34;, \u0026#34;fc.fc6.bias\u0026#34;, \u0026#34;fc.fc7.weight\u0026#34;, \u0026#34;fc.fc7.bias\u0026#34;, \u0026#34;fc.fc8.weight\u0026#34;, \u0026#34;fc.fc8.bias\u0026#34;] from collections import OrderedDict new_state_dict = OrderedDict() for i in range(0,len(model)): name = names[i] new_state_dict[name] = model[post_names[i]] return new_state_dict 完整代码 import torch import torch.nn as nn class Vgg_face_dag(nn.Module): def __init__(self): super(Vgg_face_dag, self).__init__() self.meta = {\u0026#39;mean\u0026#39;: [129.186279296875, 104.76238250732422, 93.59396362304688], \u0026#39;std\u0026#39;: [1, 1, 1], \u0026#39;imageSize\u0026#39;: [224, 224, 3]} self.conv1_1 = nn.Conv2d(3, 64, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1)) self.relu1_1 = nn.ReLU(inplace=True) self.conv1_2 = nn.Conv2d(64, 64, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1)) self.relu1_2 = nn.ReLU(inplace=True) self.pool1 = nn.MaxPool2d(kernel_size=[2, 2], stride=[2, 2], padding=0, dilation=1, ceil_mode=False) self.conv2_1 = nn.Conv2d(64, 128, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1)) self.relu2_1 = nn.ReLU(inplace=True) self.conv2_2 = nn.Conv2d(128, 128, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1)) self.relu2_2 = nn.ReLU(inplace=True) self.pool2 = nn.MaxPool2d(kernel_size=[2, 2], stride=[2, 2], padding=0, dilation=1, ceil_mode=False) self.conv3_1 = nn.Conv2d(128, 256, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1)) self.relu3_1 = nn.ReLU(inplace=True) self.conv3_2 = nn.Conv2d(256, 256, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1)) self.relu3_2 = nn.ReLU(inplace=True) self.conv3_3 = nn.Conv2d(256, 256, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1)) self.relu3_3 = nn.ReLU(inplace=True) self.pool3 = nn.MaxPool2d(kernel_size=[2, 2], stride=[2, 2], padding=0, dilation=1, ceil_mode=False) self.conv4_1 = nn.Conv2d(256, 512, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1)) self.relu4_1 = nn.ReLU(inplace=True) self.conv4_2 = nn.Conv2d(512, 512, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1)) self.relu4_2 = nn.ReLU(inplace=True) self.conv4_3 = nn.Conv2d(512, 512, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1)) self.relu4_3 = nn.ReLU(inplace=True) self.pool4 = nn.MaxPool2d(kernel_size=[2, 2], stride=[2, 2], padding=0, dilation=1, ceil_mode=False) self.conv5_1 = nn.Conv2d(512, 512, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1)) self.relu5_1 = nn.ReLU(inplace=True) self.conv5_2 = nn.Conv2d(512, 512, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1)) self.relu5_2 = nn.ReLU(inplace=True) self.conv5_3 = nn.Conv2d(512, 512, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1)) self.relu5_3 = nn.ReLU(inplace=True) self.pool5 = nn.MaxPool2d(kernel_size=[2, 2], stride=[2, 2], padding=0, dilation=1, ceil_mode=False) self.fc6 = nn.Linear(in_features=25088, out_features=4096, bias=True) self.relu6 = nn.ReLU(inplace=True) self.dropout6 = nn.Dropout(p=0.5) self.fc7 = nn.Linear(in_features=4096, out_features=4096, bias=True) self.relu7 = nn.ReLU(inplace=True) self.dropout7 = nn.Dropout(p=0.5) self.fc8 = nn.Linear(in_features=4096, out_features=2622, bias=True) def forward(self, x0): x1 = self.conv1_1(x0) x2 = self.relu1_1(x1) x3 = self.conv1_2(x2) x4 = self.relu1_2(x3) x5 = self.pool1(x4) x6 = self.conv2_1(x5) x7 = self.relu2_1(x6) x8 = self.conv2_2(x7) x9 = self.relu2_2(x8) x10 = self.pool2(x9) x11 = self.conv3_1(x10) x12 = self.relu3_1(x11) x13 = self.conv3_2(x12) x14 = self.relu3_2(x13) x15 = self.conv3_3(x14) x16 = self.relu3_3(x15) x17 = self.pool3(x16) x18 = self.conv4_1(x17) x19 = self.relu4_1(x18) x20 = self.conv4_2(x19) x21 = self.relu4_2(x20) x22 = self.conv4_3(x21) x23 = self.relu4_3(x22) x24 = self.pool4(x23) x25 = self.conv5_1(x24) x26 = self.relu5_1(x25) x27 = self.conv5_2(x26) x28 = self.relu5_2(x27) x29 = self.conv5_3(x28) x30 = self.relu5_3(x29) x31_preflatten = self.pool5(x30) x31 = x31_preflatten.view(x31_preflatten.size(0), -1) x32 = self.fc6(x31) x33 = self.relu6(x32) x34 = self.dropout6(x33) x35 = self.fc7(x34) x36 = self.relu7(x35) x37 = self.dropout7(x36) x38 = self.fc8(x37) return x38 def transform_key(state_dict): #列表来自报错内容，可复制进来更改，创建一个新字典，将key 从post_names -\u0026gt; names names = [\u0026#34;conv1_1.weight\u0026#34;,\u0026#34;conv1_1.bias\u0026#34;, \u0026#34;conv1_2.weight\u0026#34;, \u0026#34;conv1_2.bias\u0026#34;, \u0026#34;conv2_1.weight\u0026#34;, \u0026#34;conv2_1.bias\u0026#34;, \u0026#34;conv2_2.weight\u0026#34;, \u0026#34;conv2_2.bias\u0026#34;, \u0026#34;conv3_1.weight\u0026#34;, \u0026#34;conv3_1.bias\u0026#34;, \u0026#34;conv3_2.weight\u0026#34;, \u0026#34;conv3_2.bias\u0026#34;, \u0026#34;conv3_3.weight\u0026#34;, \u0026#34;conv3_3.bias\u0026#34;, \u0026#34;conv4_1.weight\u0026#34;, \u0026#34;conv4_1.bias\u0026#34;, \u0026#34;conv4_2.weight\u0026#34;, \u0026#34;conv4_2.bias\u0026#34;, \u0026#34;conv4_3.weight\u0026#34;, \u0026#34;conv4_3.bias\u0026#34;, \u0026#34;conv5_1.weight\u0026#34;, \u0026#34;conv5_1.bias\u0026#34;, \u0026#34;conv5_2.weight\u0026#34;, \u0026#34;conv5_2.bias\u0026#34;, \u0026#34;conv5_3.weight\u0026#34;, \u0026#34;conv5_3.bias\u0026#34;, \u0026#34;fc6.weight\u0026#34;, \u0026#34;fc6.bias\u0026#34;, \u0026#34;fc7.weight\u0026#34;, \u0026#34;fc7.bias\u0026#34;, \u0026#34;fc8.weight\u0026#34;, \u0026#34;fc8.bias\u0026#34;] post_names = [\u0026#34;features.conv_1_1.weight\u0026#34;, \u0026#34;features.conv_1_1.bias\u0026#34;, \u0026#34;features.conv_1_2.weight\u0026#34;, \u0026#34;features.conv_1_2.bias\u0026#34;, \u0026#34;features.conv_2_1.weight\u0026#34;, \u0026#34;features.conv_2_1.bias\u0026#34;, \u0026#34;features.conv_2_2.weight\u0026#34;, \u0026#34;features.conv_2_2.bias\u0026#34;, \u0026#34;features.conv_3_1.weight\u0026#34;, \u0026#34;features.conv_3_1.bias\u0026#34;, \u0026#34;features.conv_3_2.weight\u0026#34;, \u0026#34;features.conv_3_2.bias\u0026#34;, \u0026#34;features.conv_3_3.weight\u0026#34;, \u0026#34;features.conv_3_3.bias\u0026#34;, \u0026#34;features.conv_4_1.weight\u0026#34;, \u0026#34;features.conv_4_1.bias\u0026#34;, \u0026#34;features.conv_4_2.weight\u0026#34;, \u0026#34;features.conv_4_2.bias\u0026#34;, \u0026#34;features.conv_4_3.weight\u0026#34;, \u0026#34;features.conv_4_3.bias\u0026#34;, \u0026#34;features.conv_5_1.weight\u0026#34;, \u0026#34;features.conv_5_1.bias\u0026#34;, \u0026#34;features.conv_5_2.weight\u0026#34;, \u0026#34;features.conv_5_2.bias\u0026#34;, \u0026#34;features.conv_5_3.weight\u0026#34;, \u0026#34;features.conv_5_3.bias\u0026#34;, \u0026#34;fc.fc6.weight\u0026#34;, \u0026#34;fc.fc6.bias\u0026#34;, \u0026#34;fc.fc7.weight\u0026#34;, \u0026#34;fc.fc7.bias\u0026#34;, \u0026#34;fc.fc8.weight\u0026#34;, \u0026#34;fc.fc8.bias\u0026#34;] from collections import OrderedDict new_state_dict = OrderedDict() for i in range(0,len(state_dict)): name = names[i] new_state_dict[name] = state_dict[post_names[i]] return new_state_dict def vgg_face(weights_path=None, **kwargs): # 实例化模型，weights_path=None 表示随机初始化权重 \u0026#34;\u0026#34;\u0026#34; load imported model instance Args: weights_path (str): If set, loads model weights from the given path \u0026#34;\u0026#34;\u0026#34; model = Vgg_face_dag() if weights_path: state_dict = torch.load(weights_path) new_state_dict = transform_key(state_dict) model.load_state_dict(new_state_dict) model.eval() return model vggface = vgg_face(weights_path= r\u0026#34;D:\\Dataset\\models\\vggface.pth\u0026#34;) # 实例化模型， weights_path 是权重文件路径 ","date":"2021-12-07T17:53:33+08:00","image":"https://s2.loli.net/2021/12/07/e1lHXDzs5pMjirJ.png","permalink":"https://deathsprout.gitee.io/p/vggface-pytorch-%E5%AE%8C%E5%85%A8%E6%8C%87%E5%8D%97/","title":"Vggface Pytorch 完全指南"},{"content":"TODO   从 HugoTex theme 更换到 stack theme\n  更改 点击home会在新页面弹出 ——\u0026gt; 本页刷新\n  更改文章的归档类别，精简 categories\n  Google 百度等收录网页\n  更换挂载服务商\n垃圾gitee（ gitee page 显示index.json可能含有违规内容，删去，导致blog的搜索功能失效 ）\n  添加字数统计\n 单文章字数统计 footer 总字数和文章数统计    添加更多Markdown支持\n 支持表情 支持github格式的 !!! note 和 !!! danger github 风格的 chackbox ，明显的蓝色 √ 将KaTex支持升级    页面美化\n  字体\n 更换字体 调整字体大小    颜色\n 页面配色  底色 滑块颜色   link 颜色 赛博朋克块阴影    头像与名称居中显示\n  调整页面比例，比较喜欢缩放到80%~90%\n  使用物色到的icon\n 字数统计、显示时间的icon    修改 card 圆角 10 $\\Rightarrow$ 7\n  圆角 tag --tag-border-radius: 4px; $\\Rightarrow$ 20\n    社交\n 编写自己的 about 添加评论功能 完善其他跳转信息，如脸书可是我没有、知乎等账号链接 添加友链    记录 HugoTex theme 更换到 stack theme 添加字数统计 单文章字数统计 : 借鉴小球飞鱼，改layouts\\partials\\article\\components\\details.html\n{{ if .Site.Params.article.readingTime }} \u0026lt;div\u0026gt; {{ partial \u0026#34;helper/icon\u0026#34; \u0026#34;文本\u0026#34; }} \u0026lt;time class=\u0026#34;article-words\u0026#34;\u0026gt; {{ .WordCount }}字 \u0026lt;/time\u0026gt; \u0026lt;/div\u0026gt; 并在config.yaml设置hasCJKLanguage: true\n总字数和文章数统计 : Hugo 总文章数和总字数\n页面美化 字体 更换字体 看对应部分，简单的复制粘贴 (不过之后想换成方正新书宋或者冬青黑，英文标题部分用贝连体)\n调整字体大小 位置 assets\\scss\\variables.scss 中\n--article-font-size: 1.7rem; $\\Rightarrow$ 1.9\n颜色 页面配色 底色 :\n light ☞ 改了一圈 仅将背景色弄浅了一点 dark ☞ --body-background: #1e202b; 颜色是从中国传统色漆黑调浅  滑块颜色:\n light --scrollbar-thumb: hsla(170, 94%, 55%, 0.575); dark --scrollbar-thumb: #c91f37; 赫赤色  link 颜色 从灰色改为 --link-background-color: 1, 255, 179;\n赛博朋克块阴影 --shadow-l1: 1.4px -1.4px 0px rgba(67, 255, 230, 0.719), 0px 3px 10px rgba(0, 0, 0, 0.04), 0px 1.4px 1px rgba(253, 25, 113, 0.397); 参考 小球飞鱼 | Hugo | 看中 Stack 主题的归档功能，搬家并做修改\nCSS（层叠样式表）\n中国传统颜色手册\n小球飞鱼 | Hugo | 为 Blog 增加评论区\nNo.revi | Hugo｜引入外部字体\nNo.revi | Waline｜添加自定义表情\n","date":"2021-12-06T22:31:49+08:00","image":"https://s2.loli.net/2021/12/07/1rVtuJzys7Foecp.jpg","permalink":"https://deathsprout.gitee.io/p/blog%E6%9B%B4%E6%94%B9%E6%97%A5%E5%BF%97/","title":"Blog更改日志"},{"content":"Autoencoder 自编码器是一种神经网络，其设计目的是在压缩数据的同时，以无监督的方式学习恒等函数来重构原始输入，从而发现一种更有效的压缩表示。\n Encoder network $g_\\phi(.)$：把原始的高维输入转换成潜在的低维编码，输入大小大于输出大小。 Decoder network $f_\\theta(.)$：从编码中复原数据. bottleneck layer 是 $z=g_\\phi(x)$  花书以 $h=f(x)$ 表示编码器的输出\n  重建数据 ：$x'=f_\\theta(g_\\phi(x))$   \n维度压缩就像PCA或MF，而从编码再重建数据，好的中间表示不仅可以捕获潜在变量，也有利于整个的解压缩过程，属于是对自编码器进行了显式优化。\n参数$(\\theta,\\phi)$一起学习，令$x\\approx f_\\theta(g_\\phi(x))$,有很多方法可以量化这两个向量之间的差异，比如激活函数为sigmoid时的交叉熵，或者简单的MSE损失\n$$L_{AE}(θ,ϕ)=\\frac{1}{n}∑_{i=1}^{n}(x^{(i)}−f_θ(g_ϕ(x^{(i)})))^2$$\n 在花书中，缩写为 $L(x,g(f(x)))$\n Denoising Autoencoder (DAE) 当网络参数大于数据点数的时候，面临着过拟合的风险，为避免过拟合和提高鲁棒性，输入被随机方式加入噪声或掩盖输入向量的某些值而部分损坏，记为\n$$\\tilde{x}^{(i)} \\sim \\mathcal{M_D}(\\tilde{x}^{(i)}|x^{(i)})$$\n$\\mathcal{M_D}$定义了从真实的数据样本到噪声或损坏的数据样本的映射\n最小化 $L(x,g(f(\\tilde{x})))$，重建的数据是无噪声的  \nSparse Autoencoder 迫使模型在同一时间只有少量的隐藏单元被激活，一个隐藏层的神经元应该在大部分时间被灭活。 一隐藏层神经元被激活的比例是一个参数 $\\hat{\\rho}$ ,期望应该是一个很小的数 $\\rho$ (叫做稀疏参数),通常 $\\rho=0.05$\n这个约束是通过在损失函数中添加一个惩罚项实现的，KL散度测量了平均值为$\\rho$和$\\hat{\\rho}$两个伯努利分布（Bernoulli distributions）之间的差别。用超参数$\\beta$来控制对稀疏损失的惩罚程度。\n \n Notation： 关于自编码器符号，花书和From Autoencoder to Beta-VAE是有区别的，具体是Encoder、Decoder（相反）和中间数据表示符号（z 、h）不同.\n Structured probabilistic model 结构化概率模型使用图来描述概率分布中随机变量之间的直接相互作用,从而描述一个概率分布，这些模型也通常被称为图模型（graphical model） 。\n忽略间接相互作用，能大大减少模型的参数个数，更小的模型大大减少了在模型存储、模型推断以及在模型中采样时的计算开销。\n图描述模型结构 有向模型 有向图模型（directed graphical model），也被称为信念网络（belief network）或者贝叶斯网络（Bayesian network）。\n变量$x$的有向概率模型是通过有向无环图$\\mathcal{G}$和一系列局部条件概率分布来定义的。其中，$P_{a\\mathcal{G}}(x_i)$表示节点$x_i$的所有父节点。 $$p(x)=\\prod_ip(x_i|P_{a\\mathcal{G}}(x_i))$$\n无向模型 无向模型（undirected model），也被称为马尔可夫随机场（Markov random field，MRF）或者马尔可夫网络。\n并不是所有情况的相互作用都有一个明确的方向关系，当相互作用没有本质性的指向或者是明确的双向关系作用时，用无向模型更合适。\n对于图中的每一个团 $\\mathcal{C}$ (图中的团是图中节点的一个子集，其中的点是全连接的), 一个因子 $\\phi(\\mathcal{C})$ (也被称为团势能（clique potential）)，衡量了团中每个变量每一种可能的联合状态所对应的密切程度。它们一起定义了未归一化概率函数： $$\\tilde{p}(x)=\\prod_{\\mathcal{C\\in G}}\\phi(\\mathcal{C})$$\n配分函数 为了保证概率之和或积分为1，需要使用对应的归一化的概率分布\n$$p(x)=\\frac{1}{Z}\\tilde{p}(x)$$\n$$Z = \\int \\tilde{p}(x) dx$$\n当函数$\\phi$固定时，$Z$就是个常数，如果函数$\\phi$带有参数，$Z$就是这些参数的一个函数，$Z$被称为配分函数。\n分离与d-分离 想知道在给定其他变量子集的值时，哪些变量子集彼此条件独立。\n无向模型中，识别图中的条件独立性是非常简单的，这时候图中隐含的条件独立性称为分离。 如果变量a和b的连接路径仅涉及未观察变量，那么这些变量不是分离的。如果之间没有路径，或者所有路径都包含可观测的变量，那么他们是分离的。认为仅涉及未观察到的变量的路径是“活跃”的，包括可观察变量的路径称为“非活跃”的。\n有向模型中，这些概念叫做d-分离。\nVAE: Variational Autoencoder 不想把输入映射到一个固定的向量，而是要把它映射到一个概率分布$p_\\theta$ 。输入$x$和latent encoding vector $z$ 之间的关系可以被下面的定义：\n 先验分布 $p_\\theta(z)$ 似然分布 $p_\\theta(x|z)$ 后验分布 $p_\\theta(z|x)$  为了生成一个像是真实数据的样本$x^i$，以下步骤：\n 从先验分布$p_{\\theta^*}(z)$中抽样$z^i$ 从条件概率分布$p_{\\theta^*}(x|z=z^i)$中生成值$x^i$  最佳参数 $\\theta^*$ 是使生成真实样本数据概率最大的参数。\n$$ \\theta^* = arg \\ max_\\theta\\prod^n_{i=1}p_\\theta(x^i)$$\n通常会变形为log形式，将乘法换成加法\n$$\\theta^* = arg \\ max_\\theta\\prod^n_{i=1}log \\ p_\\theta(x^i)$$\n$$p_\\theta(x^i)=\\int p_\\theta(x^i|z)p_\\theta(z)dz$$\n但是检查所有可能的$z$值，并将对应的x的概率积分的代价是很昂贵的。引入概率分布$q_\\phi(z|x)$去近似$p_\\theta(z|x)$，用输出$x$给定输入可能的$z$\n \n如上，现在的结构很像一个自编码器\n $p_\\theta(x|z)$ 定义了一个生成模型，类似于解码器，$p_\\theta(x|z)$ 也叫概率解码器 估计的函数 $q_\\phi(z|x)$ 是概率编码器  Loss function：ELBO 可以用KL散度去量化这两个分布之间的距离，$D_{KL}(X||Y)$ ,度量用分布Y表示X时丢失了多少信息。\n我们想要参数$\\phi$，使得$D_{KL}(q_\\phi(z|x)||p_\\theta(z|x))$最小\n!!! note 为什么是 $D_{KL}(q_\\phi||p_\\theta)$ (reversed KL) 而不是 $D_{KL}(p_\\theta||q_\\phi)$ (forward KL) Bayesian Variational methods \u0026ndash; Eric Jang\n![](https://i.loli.net/2021/11/24/N15t2gJQXbAmLRE.png)   \n \n这个是学习真实分布时想要最大化的：最大化log形式的产生真实数据的可能性( $log \\ p_\\theta(x)$ ),最小化真实后验分布和估计的后验分布的差异。\n损失函数的定义如下：\n \n在变分贝叶斯方法中，这个损失函数被称为变分下界或证据下界。KL散度总是非负的，$-L_{VAE}$ 就是 $log \\ p_\\theta(x)$ 的下界。\n$$-L_{VAE}=log \\ p_\\theta(x) - D_{KL}(q_\\phi(z|x)||p_\\theta(z|x)) \\leq log \\ p_\\theta(x)$$\n最小化损失函数，就能最大化产生真实数据样本的概率下界\nReparameterization Trick （重新参数化技巧） 损失函数中调用了$z\\sim q_\\theta(z|x)$的生成样本，采样是一个随机过程，不能反向传播梯度，为了使之可以训练，引入了重新参数化技巧。 通常是将随机变量$z$转化为确定性变量 $z=\\mathcal{T}_\\theta(x,\\epsilon)$,其中$\\epsilon$是一个独立的随机变量。\n \n \n上图说明了重新参数化技巧如何使$z$采样过程可训练\n \n!!! note $\\odot$ Hadamard product Hadamard 积，只在两个相同维度的矩阵(A\\B)中定义，记作 $A\\odot B \\ or \\ A \\circ B$\n运算则是逐元素相乘 ![](https://i.loli.net/2021/11/24/cdhFupXg52fmlKM.png)  $\\beta$-VAE 如果 inferred latent representation $z$ 只对单一生成因素敏感，对其他因素不敏感，叫这种表示为解纠缠（disentangled）或因子化的（factorized）。好处是可解释性好，而且易于迁移到其他任务。\n例如，一个模型在训练人脸照片时可能会捕捉肤色、头发颜色、头发长度、情绪、是否戴眼镜以及许多其他相对独立的因素。这样的解纠缠表示对于人脸图像的生成是非常有益的。\n$\\beta$-VAE是修改的VAE,特别强调发现解纠缠的潜在因素。\n \nKKT条件下可以重写为有拉格朗日乘子$\\beta$的拉格朗日函数，上述只有一个不等式约束的优化问题等价于最大化方程$\\mathcal{F}(\\theta,\\phi,\\beta)$\n \n \n$\\beta$作为超参数，如果$\\beta=1$，和VAE相同，更高的$\\beta$值强化了对latent bottleneck的约束，能增强解纠缠。（和正则化中的权重衰减类似）\n参考  花书第十四章 花书 第16章 深度学习中的结构化概率模型 From Autoencoder to Beta-VAE Variational autoencoders.  ","date":"2021-12-05T23:49:21+08:00","image":"https://s2.loli.net/2021/12/06/diyx52IXO7aWuPw.png","permalink":"https://deathsprout.gitee.io/p/%E5%8F%98%E5%88%86%E8%87%AA%E7%BC%96%E7%A0%81%E5%99%A8/","title":"变分自编码器"},{"content":"问题描述 在一次夜间放着跑程序时被母上拔掉了电源，应当是电脑启动了系统自动更新导致系统损坏，蓝屏折腾好久最终还是重装了系统。最近需要使用matlab上的工具包matconvnet，过程中先后遇到了如下两个问题。\n  问题一     mex -setup\n    错误使用 mex 未找到支持的编译器。您可以安装免费提供的 MinGW-w64 C/C++ 编译器；请参阅安装 MinGW-w64 编译器。有关更多选项，请访问 https://www.mathworks.com/support/compilers。\n  重装系统之前，c的编译器电脑中是有MinGW以及vscode的，观察环境变量所指的位置仍然有这些文件，（但注册表那边肯定是无了）尝试重新安装了一个MinGW并配置好环境变量，仍然无用。一开始是怀疑配置文件中编辑器的版本和地址与实际情况不符，也因为我的matlab是2018b，顺手删了更新下2020a，发现问题仍然存在。\n详细报错\n\u0026gt;\u0026gt; mex -setup -V 详细模式已开。 略 ... 正在查找编译器 \u0026#39;MinGW64 Compiler (C)\u0026#39;... ... 正在查找环境变量 \u0026#39;MW_MINGW64_LOC\u0026#39;...否。 找不到已安装的编译器 \u0026#39;MinGW64 Compiler (C)\u0026#39;。 略 可以看出matlab找MinGW编辑器是以MW_MINGW64_LOC为环境变量名的,之前我都是将它的环境变量放到path里面去,在重新创建一个名为MW_MINGW64_LOC的环境变量,值设为新路径之后(D:\\for_sci\\new_minGW\\mingw64)。\n\u0026gt;\u0026gt; setenv(\u0026#39;MW_MINGW64_LOC\u0026#39;,\u0026#39;D:\\for_sci\\new_minGW\\mingw64\u0026#39;) \u0026gt;\u0026gt; mex -setup MEX 配置为使用 \u0026#39;MinGW64 Compiler (C)\u0026#39; 以进行 C 语言编译。 要选择不同的语言，请从以下选项中选择一种命令: mex -setup C++ mex -setup FORTRAN MEX 配置为使用 \u0026#39;MinGW64 Compiler (C++)\u0026#39; 以进行 C++ 语言编译。 MEX 配置为使用 \u0026#39;MinGW64 Compiler (C++)\u0026#39; 以进行 C++ 语言编译。   问题二   \u0026gt;\u0026gt; vl_compilenn(\u0026#39;verbose\u0026#39;, 1) 警告: 以后的版本中将会取消对 toolboxdir(\u0026#39;distcomp\u0026#39;) 的支持。请改用 toolboxdir(\u0026#39;parallel\u0026#39;)。 \u0026gt; In toolboxdir (line 49) In vl_compilenn (line 367) 警告: CL.EXE not found in PATH. Trying to guess out of mex setup. \u0026gt; In vl_compilenn\u0026gt;check_clpath (line 650) In vl_compilenn (line 426) \u0026#39;cl.exe\u0026#39; 不是内部或外部命令，也不是可运行的程序 或批处理文件。 错误使用 vl_compilenn\u0026gt;check_clpath (line 656) Unable to find cl.exe 出错 vl_compilenn (line 426) cl_path = fileparts(check_clpath()); % check whether cl.exe in path 这里是缺少\u0026rsquo;cl.exe'，观察我所使用的vscode，发现其并没有\u0026rsquo;cl.exe'，从而安装了vs2019，将该文件的路径加到配置文件中去。详见 Matconvnet error cl.exe not found\n  问题三   旧版本的matlab，如2015b，如果后安装的vs，配置文件里是没有相关的文件的，在max -setup -V 的时候能发现不会去寻找该编译器。经尝试，将高版本已有的配置文件选择好vs的版本，复制过去是可行的。\n","date":"2021-09-26T19:16:13+08:00","permalink":"https://deathsprout.gitee.io/p/%E9%87%8D%E8%A3%85%E7%94%B5%E8%84%91%E5%AF%BC%E8%87%B4matlab%E9%81%87%E5%88%B0%E7%9A%84%E4%BA%8C%E4%B8%89%E4%BA%8B/","title":"重装电脑导致matlab遇到的二三事"},{"content":"关键字：神经可塑性，认知可塑性，功能可塑性，突触可塑性，短时突触可塑性， LTP，稳态可塑性\n神经科学领域，可变性或可修饰性被称为可塑性（Plasticity），可塑性是神经 系统的重要特性，很少用于生命科学的其他领域。神经可塑性的表现形式涉及多 个层次，也涉及多种多样的影响因素，可以说神经可塑性的内涵非常广泛，从宏 观上遵循特定模式形成的行为逻辑，到微观上分子作用导致的结构变化等等 [1]。简要的说，神经可塑性是包括了神经组合形式改变、神经活动方式变化、神经发 育演化、神经损伤修复等一系列体现了生物体神经系统的适应性的自然属性。\n神经可塑性就物理尺度上可以分成三个层次，宏观层次、细胞层次（介观层 次）、分子层次（微观层次）。宏观层次上就影响对象还可以分成:涉及特定脑区， 影响个体生物信息加工和行为逻辑的认知可塑性;涉及非特定脑区，脑损伤后引 起功能重组的功能可塑性;以及功能重组过程中结构改变表现出的结构可塑性。 细胞层次上，神经可塑性的主要表现形式是突触可塑性，具体又可划分为突触传 递的可塑性（易化、压抑、PTP、长时程增强（Long-term potentiation（LTP））、 长时程抑制（Long-term depression（LTD）、PHP、突触缩放等等）和突触再可塑 性（描述可塑性的可塑性）。分子层次主要指神经可塑性的分子机制，大体包括 参与突触可塑性的蛋白分子和离子、形成神经可塑性的信号通路、控制神经系统 发育的遗传物质。\n宏观水平上的神经可塑性 认知可塑性 对认知可塑性的概念向前追溯，甚至可以追溯到亚里士多德在《论灵魂》中 的蜡块说，随着科技的进步，人们也意识到神经是认知活动的主要载体，但在 Hebb 提出神经学习理论之前，这些认知更多的是没有理论框架的猜想和纯粹事 实[2]。Hebb 在他的书《行为的组织》中，提出现在称为赫布定律的假设:“当神 经元A 的轴突与神经元B 很近并重复持续的参与了对B 的兴奋时，这两个神经元 或其中一个便会发生某些生长过程或代谢变化，致使A使B兴奋的效能增强了。” [3] 在后来，有相当多的研究从分子和细胞层面证明了这一假设的正确性 [4]，Markram 在赫布理论的基础上，提出了“脉冲时间依赖可塑性（STDP）”的理论， 通过神经元激发的时间顺序来影响神经元之间的联系的强弱，即突触对时间信号 具有敏感性，时间仅在数十毫秒内，正相关的突触后放电会引起突触联系增强， 负相关则相反 [5] 。\n根据赫布理论和后续的大量研究，对脑的记忆、知觉等功能的认识逐渐丰富。 就记忆形成方面来说，记忆是外界刺激对神经元集合作用的结果，以神经元集合 间突触强度改变的形式分布于大脑中，在记忆形成的过程中，神经元结构进行快 速的重构，神经元间会以快速的协同放电来加强相关神经元之间的连接，而这种 连接是广泛存在于大脑，包括纹状体、杏仁核、前额叶、小脑和内侧颞叶等，并 非集中于某个区域，但不同的解剖区域储存的记忆的类型是不同的，比如前额叶 脑区与工作记忆有关，海马与空间记忆高度相关等 [6] 。\n神经可塑性在行为方面主要体现为条件反射上，这是关联性学习，由于在记 忆提取时会激活形成该记忆的相关连接和脑区 [7] ，可以将条件反射视为通过学习 产生的记忆中的一种。经典条件反射指将正常不引起反应的条件刺激和会引起某 种反应的非条件刺激（比如食物（非条件刺激）对于分泌唾液）在时序上联系起 来。其他还有操作式条件反射（将一种动作与有意义刺激联系起来）、评价性条 件反射 [8] （当一条件刺激与另一积极或消极刺激反复联系起来，被试者对原刺激 的喜好发生改变）等类型。\n功能可塑性和结构可塑性 功能可塑性体现在神经系统功能重组的过程中，功能重组指神经系统损伤后， 有一定能力去进行结构改变和功能代偿，进而代替或部分代替受损区域原有功能 [9] 。虽然发育成熟的神经细胞不具备增殖和分裂能力，但神经元会持续具有形成 新的突触连接和修饰自身显微形态的能力。按照损伤发生的部位，可以将功能可 塑性划分为中枢神经系统功能可塑性和脊髓功能可塑性。\n相对于中枢神经系统，脊髓的功能可塑性单一且较弱，主要表现为不完全损 伤后出芽，主要包括再生性出芽（regenerating sprouting，轴突受损的神经元存活， 近侧段长出新芽）、侧枝出芽（lateral sprouting，整个神经元死亡，附近未受伤神 经元从侧枝上长出新芽）、代偿性出芽（compensatory sprouting，发育中神经元轴 突部分侧枝死亡，正常侧枝发出新芽），而完全性损伤后运动功能的恢复机制尚 不明确 [10] 。\n \n对于中枢神经系统来说，在1969 年，Luria 等人提出并完善了功能重组理论 （也被称为再训练理论），认为脑损伤后的余下部分，通过在功能上的重新组合 实现在损伤中丧失的功能 [11] 。细胞层次上的突触可塑性是损伤后参与 脑功能重组的重要神经生理过程，抗稳态和稳态可塑性都可能促进损伤后的神经 网络功能重组 [12，13] ，特别是LTP 的效率，即突触增强的效率，对神经功能重组有 重要影响，甚至直接与临床恢复程度相关 [14] 。神经元间突触连接广泛增加是应对 各种类型损伤的常见反应，可能有助于去适应因损伤造成的神经元连接数量下降， 以此来部分恢复神经网络功能，延缓症状的出现 [15] 。在神经功能重塑早期，突触 连接的增加是过量的，可以广泛的引起神经兴奋过度，进而使现存神经网络连通 性增强，有利于提升未损伤神经网络效率 [15] 。在神经功能重塑后期，根据稳态可 塑性和STDP 的双向调节，有效的降低过量的突触连接，选择性的保留并增强活 跃的突触连接，实现功能和结构的重塑 [15] 。\n分子细胞水平上的神经可塑性 本部分主要介绍神经可塑性中最重要的突触可塑性，鉴于属于细胞水平的表 象和属于分子水平的机制不适合分开阐述，故将两个层次上的神经可塑性放在一 起。\n突触可塑性及机制 突触可塑性是经验依赖性可塑性，这些突触多为化学性突触，其表现与个体 神经元历史活动高度相关，常规意义上的突触可塑性特指由LTP 或LTD 表现出 的经验依赖性的突触效能改变。这里将之含义扩大，除了突触传递的可塑性（比 如LTP、LTD、短时程突触可塑性、突触缩放等），还包括突触再可塑性 [16，17，18] 。\n短时突触可塑性 从简单的无脊椎动物到哺乳动物，几乎每一个突触都可以观察到多种形式的、 持续时间从毫秒到几分钟不等的短期突触可塑性 [19] ，表现为突触易化、突触压抑、 强直后增强这些形式。突触后电位在相邻数百毫秒的时间间隔上对后续刺激反应 的增强，叫突触易化（synaptic facilitation），相反，对后续刺激反应减弱叫突触 压抑（synaptic depression）。长串的高频刺激往往会先引起突触压抑，数秒后再 形成持续数分钟乃至数十分钟的突触后电位增强，被称为强直后增强（posttetanic potentiation） [20] 。\n在研究的所有突触中，短时突触可塑性都被证明是突触前机制引起的，易化、 增强和强直后增强具体表现是统计上动作电位释放的递质量子数量增加，没有突 触后的效应，作为量子的囊泡本身大小也没有变化，在统计上表现出的数量增加 反应了突触前囊泡预备池中释放概率的增加 [19] 。Katz 和Miledi（1968）认为可能 在初次刺激后仍有Ca2+ 存在于突触前神经元中，并导致后续更大的钙信号引起突 触强度变化 [21] ，这在后来完善成为残留钙假说，并有诸多研究观察到与该假说一 致的促进作用。Ca2+ 离子在此过程中至关重要，囊泡融合的核心是由syt1 （syntaxin-1）、突触囊泡蛋白和SNAP-25 形成复合物共同将囊泡和质膜相连，而 复合物SNARE 对Ca2+ 敏感，Ca2+ 浓度提升能促进囊泡释放 [22] 。Schneggenburger 和Neher（2000）研究发现在大型突触末端的杯状突起处，仅10μM 幅度的Ca2 + 的阶梯状升高诱导了快速的递质释放，能在3ms 内消耗大约80％的囊泡预备池 [23] ，表明Ca2 + 的短时增多能触发神经递质的快速释放。在短时间内，初次刺激过 后突触前神经元Ca2 + 浓度上升，产生易化，但过多的Ca2 + 将囊泡预备池耗竭， 引起短时间的压抑，而高频刺激先引起突触压抑，后续的强直后增强对应的是囊 泡预备池的增大（以及Ca2 + 的积聚） [20] 。\n突触可塑性\u0026ndash;LTP 突触可塑性最受关注的现象是长时程增强（LTP）和长时程抑制（LTD），尤 其是LTP，自从1973 年在海马中发现长时程增强以来 [24] ，大量关键相关论文发 表，LTP 目前为学习和记忆提供了一个有说服力的细胞模型。经历高频刺激的突 触，其会产生长达数小时甚至数天的兴奋性突触电位幅度增强，这种现象被称为 长时程增强。后续的研究发现LTP 有多种特性，McNaughton（1978）和Levy and Stewart（1979）先后报道LTP 具有“协同性（（1）该突触的前神经元兴奋并释放 神经递质;（2）该突触后神经元处于去极化状态。某突触的LTP 可以在上述这两 种条件同时存在时产生）”和“关联性（强刺激作用后，一定时间内一个弱刺激 也能引发LTP 的性质）”，以及“输入特异性（LTP 只发生在经历刺激的突触上， 不发生在同一突触后神经元的其他未受刺激的突触上）”，这些发现将LTP 视为 赫布假设实现的过程 [25] 。接着一方面通过向突触后神经元注入去极化电流 （Gustafsson，1987），一方面通过超极化等方式防止LTP 期间产生去极化电位 （Malinow、Miller, 1986），证明了产生LTP 不需要一定存在高频刺激，只有两 个硬性要求:突触刺激和突触后去极化 [25] 。这些特性使得LTP 适用于调节突触连 接网络，动物的个体经历能够在单个突触水平上改变所在突触连接网络上每个突 触的强度，比如输入特异性能使独立调控突触后神经元与不同突触前神经元形成 的连接强度成为可能;协同性可以使单一输入信号同时去极化复数突触后神经元， 调节一组突触连接的强度;关联性使同时的输入信号之间可以互相影响 [26] 。大多 表现LTP 的突触也表现一种或多种形式的LTD，其机制和效应虽然不同，但LTD 与LTP 两者都描述了一类现象。\n目前认为LTP 的分子机制（见图2）同时涉及突触前和突触后的因素，不过 突触前因素没有突触后因素重要，根据LTP 的过程可以划分为LTP 的诱导、维 持和表达三个阶段，根据维持的持续时间又将LTP 分成E-LTP（Early Phase LTP） 和L-LTP（Late Phase LTP）。\nLTP 和LTD 的突触前因素除了部分与短时效应类似，表现在突触前神经元 神经递质释放量的增加/减少上之外 [20] ，一些突触的突触后神经元会有一个逆行 信号“NO”促进突触前神经元释放神经递质 [25] 。突触后因素中，NMDA 受体对 LTP 的诱导至关重要，如果敲除掉NMDAR1 基因，LTP 无法发生 [27] 。NMDA 型 谷氨酸受体在神经元处于静息电位时被Mg2+ 占据，而在去极化时与Mg2+ 分离（突 触后去极化），此时NMDA 受体与神经递质谷氨酸结合（突触刺激），能引起Ca2+ 内流，这是LTP 的诱导过程。\nE-LTP 的刺激量小，持续时间短，这个过程没有新蛋白质的合成，而L-LTP 刺激量大，产生后维持的持续时间能超过24 小时，会有cAMP、PKA 等的参与， 最后合成蛋白质实现表达。钙离子内流会激活两个关键的信号蛋白，CaMKII 和 蛋白激酶PKC。钙与钙调蛋白结合激活CaMKII 后，CaMKII 磷酸化细胞膜上的 AMPA 型通道受体，增强其通道电导，使得突触后膜上的AMPA 受体对刺激反 应幅度更大 [28] 。这些AMPA 受体并非完全位于细胞膜上，沉默突触的发现表明 在LTP 发生之前，突触后的终扣只有部分有AMPA 受体，都有NMDA 受体但是 被Mg2+ 堵塞，而激活的蛋白激酶PKC 和CaMKII 能导致含有AMPA 受体的囊泡 与细胞膜融合，将AMPA 受体插入突触后膜上，CaMKII 还能将AMPA 的结合 蛋白stargzin 磷酸化，使stargzin 结合PSD95，引导AMPA 受体处在突触后膜区 域，使该突触的效能上升 [28] 。这里的PSD（postsynaptic density）指的是突触后致 密区域，根据Bosch 等人的研究，PSD 在LTP 诱导后一个小时左右出现，PSD 的形成会改变突触可塑性的规则，这可能能解释为什么突触可塑性的规则会随时 间改变 [29] 。L-LTP 在此基础上，强烈的钙离子内流还会激活存在于突触旁的 mRNA 翻译产生PKMζ，该蛋白再磷酸化囊泡上的AMPA 蛋白。这是LTP 的维 持过程，CaMKII 能够自身磷酸化，在没有钙离子存在的情况下也能长时间保持 活性，而PKMζ没有调控域，只靠亚单位催化，在激活后无法自主的失活，同 样因为其能调控突触位置蛋白的翻译，能在没有钙离子存在的情况下保持较高的 水平 [28] 。\n \n值得注意的是，CaMKII 被发现占据脑蛋白量的2%[ 30] ，在突触中调节许多 的过程，应当有严格调节CaMKII 的机制存在，可能涉及两种内源性的分子抑制 剂CaMK2N1 和CaMK2N2[ 31] 。在一项新的研究中，研究者发现在LTP 诱导产生 后，CaMK2N2 基因呈现分级上调，意味着CaMK2N2 蛋白可能会在LTP 过程中 发挥作用，也许会参与形成突触的再可塑性 [32] 。\nLTP 的最后一个阶段对应蛋白质性质改变，在L-LTP 中还有新蛋白质合成 和新突触的形成。重复刺激引起的钙离子信号激活腺苷酸环化酶，进而激活 cAMP/PKA 信号途径，PKA 的调节亚基脱落后，PKA 的催化亚基进入细胞核， 磷酸化CREB-1 转录因子，开启部分相关基因的表达。\n对LTP 的影响因素还有很多，Cortese 等人发现丰富的环境提高了不同行为 任务中探索记忆和学习的表现，而且丰富的环境可以增强老年大鼠的mGluR5 依 赖性LTP[ 33] 。\n稳态可塑性 另外突触传递的可塑性形式还有稳态可塑性，突触前稳态可塑性（PHP），主 要是由于神经递质受体功能或动作电位活性受损引起的，神经递质受体水平的绕 动都会导致相应神经递质释放的增多 [34] 。谷氨酸受体干扰实验中神经递质释放增 加精确的补偿了施加的干扰 [35] ，表明PHP 过程含有逆行的跨突触信号系统 [34] ， 但目前对PHP 机制的了解不多，2017 年有实验组发现信号素2b 作为突触前 plexin B 的受体，形成缩写为Sema2b–PlexB 的跨突触信号传导通路 [36] 。\n突触后稳态可塑性表现形式是神经递质受体的稳态调节，即突触缩放。突触 缩放这一现象，具体是指神经元细胞在特定条件下会调节细胞上所有突触连接的 强度，不同突触之间的相对效能不发生变化，以此响应长时间的变化 [37] 。突触后 神经元上活动总体的短期持续下降会导致突触缩放，总突出强度净增长，长期不 活动会导致相反的趋势，而如果将一个神经元的全部输入阻断，该神经元表现出 超敏感性，可兴奋性和突触输入增强 [37] 。\n参考文献 [1]吴馥梅.脑神经可塑性[J].现代特殊教育,1999(06):12-13.\n[2] 黄家裕. 认知神经的可塑性:赫布理论的哲学意蕴[J]. 哲学动态, 2015, 000(009):104-108.\n[3] Hebb, D. (1949)The Organisation of Behaviour, Wiley\n[4] Bi, G. and Poo, M. (2001) Synaptic modification by correlated activity:Hebb’s postulate revisited.Annu. Rev. Neurosci.24, 139–166\n[5] Roberts P D , Bell C C . Spike timing dependent synaptic plasticity in biological systems[J]. Biological Cybernetics, 2002, 87(5-6):392-403.\n[6] Howard Eichenbaum 著，周仁来等译，杨治良审校:记忆的认知神经科学\u0026ndash;导 论。北京师范大学出版社\n[7] A R C , A F D , A S E P , et al. Attention-related activity during episodic memory retrieval: a cross-function fMRI study[J]. Neuropsychologia, 2003, 41( 3):390-399.\n[8] De Houwer J , Thomas S , Baeyens F . Associative learning of likes and dislikes: A review of 25 years of research on human evaluative conditioning[J]. Psychological Bulletin, 2001, 127(6):853-869.\n[9] Ward N S . Mechanisms underlying recovery of motor function after stroke[J]. Postgraduate Medical Journal, 2005, 81(958):510-.\n[10] 肖志峰,陈冰,赵燕南,李佳音,韩素芳,陈艳艳,戴建武.脊髓损伤再生研究进展 ——搭建脊髓损伤修复的希望之桥[J].中国科学:生命科学,2019,49(11):1395-1408.\n[11] 缪鸿石. 中枢神经系统(CNS)损伤后功能恢复的理论(一)[J]. 中国康复理论 与实践, 1995, 001(001):1-4.\n[12] Desai, N.S.; Cudmore, R.H.; Nelson, S.B.; Turrigiano, G.G. Critical periods for experience-dependent synaptic scaling in visual cortex. Nat. Neurosci. 2002, 5, 783– 789.\n[13] Turrigiano, G. Homeostatic synaptic plasticity: Local and global mechanisms for stabilizing neuronal function. Cold. Spring Harb. Perspect. Biol. 2012, 4, a005736.\n[14] Mori, F.; Kusayanagi, H.; Nicoletti, C.G.; Weiss, S.; Marciani, M.G.; Centonze, D. Cortical plasticity predicts recovery from relapse in multiple sclerosis. Mult. Scler. 2014, 20, 451–457.\n[15] Stampanoni Bassi, M.; Iezzi, E.; Gilio, L.; Centonze, D.; Buttari, F. Synaptic Plasticity Shapes Brain Connectivity: Implications for Network Topology. Int. J. Mol. Sci. 2019, 20, 6193.\n[16] Citri A , Malenka R C . Synaptic Plasticity: Multiple Forms, Functions, and Mechanisms[J]. Neuropsychopharmacology, 2008, 33(1):18-41.\n[17] Singh P, Heera PK, Kaur G.Expression of neuronal plasticity markers in hypoglycemia induced brain injury[J].Mol Cell Biochem2003, 247 (1) :69-74.\n[18] 王韶莉,陆巍.再可塑性在学习记忆中作用的研究进展[J].生理学 报,2016,68(04):475-482.\n[19]Zucker R S , Regehr W G . SHORT -TERM SYNAPTIC PLASTICITY[J]. Annual Review of Physiology, 2002, 64(1):355-405.\n[20]Nicholls J G . From Neuron to Brain[M]. Sinauer Associates, 2001.\n[21]Katz B, Miledi R. 1968. The role of calcium in neuromuscular facilitation. J. Physiol. 195:481–92\n[22]Jackman S L , Regehr W G . The Mechanisms and Functions of Synaptic Facilitation[J]. Neuron, 2017, 94(3):447-464.\n[23]Schneggenburger R , Neher E . Intracellular calcium dependence of transmitter release rates at a fast central synapse[J]. Nature, 2000, 406(6798):889-893.\n[24]Mechanisms[J]. Neuropsychopharmacology, 2008, 33(1):18-41.\n[25] Nicoll, Roger A . A Brief History of Long-Term Potentiation[J]. Neuron, 2017, 93(2):281-290.\n[26]Liqun Luo. Principles of Neurobiology[J]. crc press, 2015.\n[27]Tsien, J. Z., Huerta, P. T., \u0026amp; Tonegawa, S. (1996). The essential role of hippocampal CA1 NMDA receptor–dependent synaptic plasticity in spatial memory.Cell,87(7), 1327-1338.\n[28]Lisman J , Yasuda R , Raghavachari S . Mechanisms of CaMKII action in long- term potentiation[J]. Nature Reviews Neuroscience, 2012, 13:2358.\n[29]Bosch M , Castro J , Saneyoshi T , et al. Structural and Molecular Remodeling of Dendritic Spine Substructures during Long-Term Potentiation[J]. Neuron, 2014, 82(2):444-459.\n[30]Nikolai, Otmakhov, and, John, \u0026amp; Lisman. Measuring CaMKII concentration in dendritic spines[J]. Journal of Neuroscience Methods, 2012.\n[31] B.H. Chang, S. Mukherji, T.R. Soderling. Calcium/calmodulin-dependent protein kinase II inhibitor protein: localization of isoforms in rat brain[J]. Neuroscience, 2001, 102(4):0-777.\n[32]Sanhueza, M.CaMKII inhibitor 1 (CaMK2N1) mRNA is upregulated following LTP induction in hippocampal slices[J]. Neurosciences , 2020.\n[33]Cortese G P , Olin A , O’Riordan, Kenneth, et al. Environmental Enrichment Improves Hippocampal Function in Aged Rats by Enhancing Learning and Memory, LTP and mGluR5-Homer1c Activity[J]. Neurobiology of Aging, 2017:S0197458017303731.\n[34] Delvendahl I , Müller, Martin. Homeostatic plasticity—a presynaptic perspective[J]. Current Opinion in Neurobiology, 2019, 54:155-162.\n[35]Frank CA, Kennedy MJ, Goold CP, Marek KW, Davis GW: Mechanisms underlying the rapid induction and sustained expression of synaptic homeostasis. Neuron 2006, 52:663-677.\n[36] Orr B O , Fetter R D , Davis G W . Retrograde semaphorin-plexin signalling drives homeostatic synaptic plasticity[J]. Nature, 2017, 550(7674):109-113.\n[37] Citri A , Malenka R C . Synaptic Plasticity: Multiple Forms, Functions, and Mechanisms[J]. Neuropsychopharmacology, 2008, 33(1):18-41.\n","date":"2021-06-25T20:54:26+08:00","image":"https://s2.loli.net/2021/12/05/EAlSkpHZeyqDF24.png","permalink":"https://deathsprout.gitee.io/p/%E7%A5%9E%E7%BB%8F%E5%8F%AF%E5%A1%91%E6%80%A7/","title":"神经可塑性"},{"content":"神经生物   中枢神经系统 central nervous system CNS\n  脑 brain\n 大脑皮质 cerebral cortex 基底节 basel ganglia 海马 hippocampus 杏仁核 amygdala 丘脑 thalamus 下丘脑 hypothalamus 小脑 cerebellum 脑干 brainstem  中脑 midbrain 脑桥 pons 延髓 medulla      脊髓 spinal cord\n    神经解剖学 neurianatomical 组织学切面\n 冠状切面 coronal section：又名横截面，拦腰的那种 矢状切面 sagittal section： 从头劈到尾，左右分开 水平切面 horizontal section：字面意思    神经节 ganglia（ganglion（组织、医学范围，说神经节细胞一般是ganglion cell））：神经元集群\n  神经元 neuron\n 胞体 soma 神经突起 neuronal process  树突 dendrite  树突棘 dendritic spine ：树突上的小突起   轴突 axon  突触前末梢 presynaptic        神经胶质细胞 glia\n 少突胶质细胞 oligodendrocyte 施万细胞 schwann cell 星型胶质细胞 astrocyte 小胶质细胞 microglia     白质 white matter ：由少突胶质细胞和有髓轴突共同组成，髓鞘（myelin sheath）中富含脂质，呈现白色。 灰质 gray matter    突触 synapse\n 化学突触 chemical synapse  神经递质 neurotransmitter  乙酰胆碱 acetylcholine ACh   突触间隙 synaptic cleft 突触囊泡 synaptic vesicle 突触后特化 postsynaptic specialization （也称突触后致密 postsynaptic density）   电突触 electrical synapse  间隙链接 gap junction  连接子蛋白 connexin        锥体神经元 pyramidal neuron\n  动态极化理论 theory of dynamic polarization\n  膜电位 member potential\n  神经冲动 nerve impulse\n  电位\n 动作电位 action potential 分级电位 graded potential（也称局部电位）  突触电位 （在突触后膜对神经递质的响应位点上产生）  突触传递 synaptic transmission ：   受体电位 receptor potential      传入神经 afferent\n  传出神经 efferent\n   兴奋性神经元 excitatory neuron 抑制性中间神经元 inhibitory interneuron 投射神经元 projection neuron ：轴突将神经系统两个不同区域连接在一起    回路基序\n 前馈兴奋 feedforward excitation 前馈抑制 feedforward inhibition 反馈抑制 feedback inhibition 复发性抑制（交叉抑制） recurrent（cross） inhibition 侧抑制 lateral inhibition 去抑制 disinhibition      脑沟 fissure\n 额叶 frontal lobe 顶叶 parietal lobe 颞叶 temporal lobe 枕叶 occipital lobe    拓扑映像 topographic map\n  扰动实验 perturbation experiment\n 功能失去实验 loss-of-function experiment 功能获得实验 gain-of-function experiment    离子通道 ion channel\n  电化学梯度 electrochemical potential\n  被动运输 passive transport\n  通透性 permeability\n   阳离子 cation 阴离子 anion    峰电位 spike （动作电位 action potential）\n  阈值 threshold\n 阈下刺激 subthreshold stimulus 阈上刺激 suprathreshold stimulus    不应期 refractory period ：K+离子通道激活延迟和Na+离子通道失活导致的，不能从头产生另一个动作电位的时期。\n  跳跃式传导 saltatory conduction ：有髓轴突的动作电位会在节点之间跳跃前进\n 髓鞘 myelin sheath 郎飞结 nodes of Ranvier       突触易化 synaptic facilitation 突触压抑 synaptic depression 强直后增强 posttetanic potentiation    河豚毒素 tetrodotoxin TTX ： 有效阻断电压门控的Na离子通道\n  膜片钳记录技术 patch clamp recording\n  突触结合蛋白 synaptotagmin\n  存储池 reserve pool\n  易释放池 readily releasable pool\n  容积传递 volume transmission ：神经递质可能在突触外的胞外空间影响周围多个细胞\n   空间整合 spatial integration 时间整合 temporal integration    视神经 optic nerve\n 感光细胞 photoreceptor  视杆细胞 rod 视锥细胞 cone 中央凹   视网膜节细胞 retinal ganglion cell RGC ：输出层，通过轴突将信息传递给大脑，轴突成束即视神经 双极细胞 bipolar cell ：将信号从感光细胞传递到RGC 水平细胞 horizontal cell      发色团 chromophore\n  侧抑制 lateral inhibition\n  树突平铺 dendritic tiling ：许多种视网膜节细胞和无长突细胞的树突布满视网膜的同时彼此没有重叠\n  对立颜色视网膜节细胞 color-opponent RGC ： 蓝-黄、红-绿\n   顶盖 tectum ： 两栖和低等脊椎动物RGC在脑中的目标脑区\n  视网膜拓扑映射 retinotopy\n  内源信号成像 intrinsic signal imaging ： 利用代谢特征，包括血流速和血氧水平来反应神经元活动。\n  眼优势 ocular dominance ：许多输入皮质中第4层的皮质神经元只对来自一只眼的输入有很强的偏好性。\n  梭状脸部区域 fusiform face area ：一个优先被人脸图像激活的区域。\n  带缩写的视觉相关区域\n 外侧膝状体核 lateral geniculate nucleus LGN 颞中视觉区 middle temporal visual area MT ：MT神经元对于运动方向特别敏感 外侧顶内沟区 lateral intraparietal area LIP：放电的频率能预料眼将要运动的方向，LIP神经元活动与决定下达有因果关系。    轴突导向分子 axon guidance molecule\n  视交叉 optic chiasm ：所有脊椎动物都有大量RGC轴突穿越中轴线，投射到异侧脑\n 对侧 contralaterally 投射：人鼻侧视网膜轴突穿过中轴线（60%） 同侧 ipsilateral ：颞侧（40%）    气体分子 odorant\n  嗅纤毛 olfactory cilium\n  嗅球 olfactory bulb\n  多态性 polymorphism\n  感知对象 percept\n  原位杂交 in situ hybridization ：用核酸探针在整块组织上探测基因表达\n  等位排斥 allelic exclusion ：特定ORN中，起功能的气味受体的mRNA仅仅转录自一对同源染色体的其中一个。\n   僧帽细胞 mitral cell 簇绒细胞 tufted cell 梨形皮质 piriform cortex 投射神经元 projection neurin PN ：嗅觉信息由PN转寄到更高的嗅觉中枢 局部中间神经元 local interneuron LN ：    增益控制 gain control ：指通过调节系统输入输出的关系，使输出限制在有限动态范围内的过程。\n  逆向跨突触追踪 retrograde trans-synaptic tracing ：标记给定神经元发送直接信号的突触前神经元\n  定向的、面向\u0026hellip;的 oriented : oriented bars\n   计算神经科学  反向传播 back propagation 主成分分析 principal component analysis 编码空间 coding space 基于规范 Norm-Based Hierarchical Model and X (HAMX): 层次、等级制度 hierarchy 调谐 tuned 重铸 recast 稀疏 sparseness 表现超过、性能优于 outperformed 连通性 connectivity 封闭性 closedness 不透明的、难理解的、晦涩的 opaque  认知神经科学    论文中杂项  信条 tenet 基本机制 elementary mechanisms 专门、具体的 particularly 可论证的 arguably 可观、显著的、实质性的 substantial 说明的、解释的 explanatory 命名系统、术语集 nomenclature  术语 terminology   公开的 overt 范例 paradigm    昏迷 comatose  弥漫的 diffuse 假定 postulates 交织 intertwined 隐含的 underlying 特性、财产 properties 杠杆的、杠杆作用 leveraged 老化 aging 精神病(学)的 psychiatric 类似于 akin to 复杂的 sophisticated 死胡同 cul-de-sac 统一 unifying 粗略的、粗糙的 coarsely 精细尺度 finer-scale 为了便于说明 For ease of exposition 艺术级的、尖端水平的、最先进的 state-of-the-art 妨碍 hampered 变形的 morphing 精细的；精巧的 subtler 负责的；易控制的；经得起检验的 amenable 退化 degrad 处于个人的原因 for its own sake  物种专有名词  猕猴 macaque  ","date":"2021-06-23T12:46:06+08:00","permalink":"https://deathsprout.gitee.io/p/%E7%A5%9E%E7%BB%8F%E7%94%9F%E7%89%A9%E5%92%8C%E8%AE%A1%E7%AE%97%E7%A5%9E%E7%BB%8F%E8%8B%B1%E6%96%87%E5%90%8D%E8%AF%8D/","title":"神经生物和计算神经英文名词"},{"content":"问题如下： |使用Python或者Perl编程，完成以下任务：\n 1.tab是Trichoderma reesei QM6a的annotation文件，2.obo是GO的ontology文件，根据ontology文件中所记录的GO关系：  (a)\t获得已注释的所有基因属于哪一个GO的全部列表\n(b)\t计算Trichoderma reesei QM6a中每一个GO分别有多少个基因。\nDEG.txt中记录了某一次转录组分析的差异基因结果。请计算：  (a)\t每一个GO中所属的基因显著上调和下调的个数有多少？\n(b)\t哪些GO发生了显著的上调或者下调的富集？\n文件解释： 先说一下文件，1.tab是如下图所示的annotation文件，大概两万多行，有proteinId，gotermId，goName，gotermType，goAcc的信息，其中本次用到的的是proteinId和goAcc。goAcc是该基因所属的GO号，形式是GO:加七位数字。一个基因能对应多个GO id，一个GO id也能对应多个基因。\nproteinId\tgotermId\tgoName\tgotermType\tgoAcc 1673\t3504\ttranslational initiation\tbiological_process\tGO:0006413 1673\t2855\tcytoplasm\tcellular_component\tGO:0005737 1673\t1108\ttranslation initiation factor activity\tmolecular_function\tGO:0003743 1673\t1096\tRNA binding\tmolecular_function\tGO:0003723 1692\t3503\tprotein biosynthesis\tbiological_process\tGO:0006412 1692\t2953\tribosome\tcellular_component\tGO:0005840 1692\t2746\tintracellular\tcellular_component\tGO:0005622 1692\t1107\tstructural constituent of ribosome\tmolecular_function\tGO:0003735 1692\t1096\tRNA binding\tmolecular_function\tGO:0003723 1702\t3444\ttranscription\tbiological_process\tGO:0006350 1702\t1233\tDNA-directed DNA polymerase activity\tmolecular_function\tGO:0003887 1702\t1056\tDNA binding\tmolecular_function\tGO:0003677 1702\t10782\tsigma DNA polymerase activity\tmolecular_function\tGO:0019984 1702\t8197\ttheta DNA polymerase activity\tmolecular_function\tGO:0016452 1702\t8196\tnu DNA polymerase activity\tmolecular_function\tGO:0016451 1702\t8195\tkappa DNA polymerase activity\tmolecular_function\tGO:0016450 1702\t8194\tlambda DNA polymerase activity\tmolecular_function\tGO:0016449 1702\t8193\tmu DNA polymerase activity\tmolecular_function\t2.obo记录了GO之间的上下级关系，文件本身三十几万行，47125个GO，如下所示的[Term]表示一个GO，随后id：GO：XXXXXXX就是这个GO的 id，namespace就是这个GO属于本体论里三个顶级GO的哪一个，比如GO:0000001属于biological_process。\n第一题的（a）就是要找到所有GO的所有上级GO（或者说父亲），最终归宿到biological_process、molecular_function、cellular_component。\nformat-version: 1.2 data-version: releases/2018-04-12 subsetdef: goantislim_grouping \u0026#34;Grouping classes that can be excluded\u0026#34; subsetdef: gocheck_do_not_annotate \u0026#34;Term not to be used for direct annotation\u0026#34; subsetdef: gocheck_do_not_manually_annotate \u0026#34;Term not to be used for direct manual annotation\u0026#34; subsetdef: goslim_agr \u0026#34;AGR slim\u0026#34; subsetdef: goslim_aspergillus \u0026#34;Aspergillus GO slim\u0026#34; subsetdef: goslim_candida \u0026#34;Candida GO slim\u0026#34; subsetdef: goslim_chembl \u0026#34;ChEMBL protein targets summary\u0026#34; subsetdef: goslim_generic \u0026#34;Generic GO slim\u0026#34; subsetdef: goslim_goa \u0026#34;GOA and proteome slim\u0026#34; subsetdef: goslim_metagenomics \u0026#34;Metagenomics GO slim\u0026#34; subsetdef: goslim_mouse \u0026#34;Mouse GO slim\u0026#34; subsetdef: goslim_pir \u0026#34;PIR GO slim\u0026#34; subsetdef: goslim_plant \u0026#34;Plant GO slim\u0026#34; subsetdef: goslim_pombe \u0026#34;Fission yeast GO slim\u0026#34; subsetdef: goslim_synapse \u0026#34;synapse GO slim\u0026#34; subsetdef: goslim_virus \u0026#34;Viral GO slim\u0026#34; subsetdef: goslim_yeast \u0026#34;Yeast GO slim\u0026#34; subsetdef: gosubset_prok \u0026#34;Prokaryotic GO subset\u0026#34; subsetdef: mf_needs_review \u0026#34;Catalytic activity terms in need of attention\u0026#34; subsetdef: termgenie_unvetted \u0026#34;Terms created by TermGenie that do not follow a template and require additional vetting by editors\u0026#34; subsetdef: virus_checked \u0026#34;Viral overhaul terms\u0026#34; synonymtypedef: syngo_official_label \u0026#34;label approved by the SynGO project\u0026#34; synonymtypedef: systematic_synonym \u0026#34;Systematic synonym\u0026#34; EXACT default-namespace: gene_ontology remark: cvs version: use data-version remark: Includes Ontology(OntologyID(Anonymous-35)) [Axioms: 230 Logical Axioms: 228] remark: Includes Ontology(OntologyID(OntologyIRI(\u0026lt;http://purl.obolibrary.org/obo/go/never_in_taxon.owl\u0026gt;))) [Axioms: 18 Logical Axioms: 0] ontology: go [Term] id: GO:0000001 name: mitochondrion inheritance namespace: biological_process def: \u0026#34;The distribution of mitochondria, including the mitochondrial genome, into daughter cells after mitosis or meiosis, mediated by interactions between mitochondria and the cytoskeleton.\u0026#34; [GOC:mcc, PMID:10873824, PMID:11389764] synonym: \u0026#34;mitochondrial inheritance\u0026#34; EXACT [] is_a: GO:0048308 ! organelle inheritance is_a: GO:0048311 ! mitochondrion distribution [Term] id: GO:0000002 name: mitochondrial genome maintenance namespace: biological_process def: \u0026#34;The maintenance of the structure and integrity of the mitochondrial genome; includes replication and segregation of the mitochondrial chromosome.\u0026#34; [GOC:ai, GOC:vw] is_a: GO:0007005 ! mitochondrion organization [Term] id: GO:0000003 name: reproduction namespace: biological_process alt_id: GO:0019952 alt_id: GO:0050876 def: \u0026#34;The production of new individuals that contain some portion of genetic material inherited from one or more parent organisms.\u0026#34; [GOC:go_curators, GOC:isa_complete, GOC:jl, ISBN:0198506732] subset: goslim_agr subset: goslim_chembl subset: goslim_generic subset: goslim_pir subset: goslim_plant subset: gosubset_prok synonym: \u0026#34;reproductive physiological process\u0026#34; EXACT [] xref: Wikipedia:Reproduction is_a: GO:0008150 ! biological_process [Term] id: GO:0000005 name: obsolete ribosomal chaperone activity namespace: molecular_function def: \u0026#34;OBSOLETE. Assists in the correct assembly of ribosomes or ribosomal subunits in vivo, but is not a component of the assembled ribosome when performing its normal biological function.\u0026#34; [GOC:jl, PMID:12150913] comment: This term was made obsolete because it refers to a class of gene products and a biological process rather than a molecular function. synonym: \u0026#34;ribosomal chaperone activity\u0026#34; EXACT [] is_obsolete: true consider: GO:0042254 consider: GO:0044183 consider: GO:0051082 ...... ...... 这最后的is_a: GO：XXXXXXX! 意思是本GO是后面这个GO的一部分，是它的下级，relationship: part_of GO：XXXXXXX!是同样的意思。\n有些GO和其他GO什么关系都没有，最后有个is_obsolete: true，说明它过时了，同时还会在def:最前面加上 OBSOLETE 。\n还有一些其他的关系，在这里暂时无须明白里面的所有内容,可以去看看一文极速读懂 Gene Ontology，老师说找relationship: part_of、is_a:建关系即可。\n#DEG.txt中记录了某一次转录组分析的差异基因结果 gene_id\tA\tB\tp-value\tFDR\tsignificance 105313\t476.125\t2.01685\t0\t0\tDOWN 81082\t188.012\t0.388781\t4.44E-16\t0.000106687\tDOWN 70204\t30.8683\t0.0378778\t3.33E-15\t0.000106687\tDOWN 112031\t74.6035\t0.708632\t4.66E-15\t0.000106687\tDOWN 122511\t1065.56\t8.16165\t1.44E-14\t0.000106687\tDOWN 49274\t106.879\t1.05212\t1.44E-14\t0.000106687\tDOWN 68803\t186.04\t2.46745\t1.69E-14\t0.000106687\tDOWN 123914\t149.261\t1.65829\t3.82E-14\t0.000106687\tDOWN 59362\t56.5321\t0.138204\t4.22E-14\t0.000106687\tDOWN 105882\t195.885\t0.663057\t5.64E-14\t0.000106687\tDOWN 108676\t703.881\t2.29893\t1.20E-13\t0.000106687\tDOWN 60489\t1.33266\t157.422\t4.06E-13\t0.000106687\tUP 66935\t2.52345\t123.558\t2.10E-12\t0.000106687\tUP 76659\t214.616\t1.82799\t3.86E-12\t0.000106687\tDOWN 解决问题 获得已注释的所有基因属于哪一个GO的全部列表 #引入包 import os import numpy as np import pandas as pd import csv import re import time #一开始想减少耗时，把2.obo中用不到的，即除is_a:|relationship: part_of|id: 的行全删了。 with open(\u0026#39;2.obo\u0026#39;,\u0026#39;r\u0026#39;) as f: while True: line = f.readline() strline = str(line) h = re.match(\u0026#39;is_a: GO|relationship: part_of|id: GO\u0026#39;,strline) if h is not None : clean = open(\u0026#39;2_clean.obo\u0026#39;,\u0026#39;a\u0026#39;) clean.write(line) clean.close() if not line: break f.close() #字典法 def dictGO(): father_list =[] with open(\u0026#39;2_clean.obo\u0026#39;,\u0026#39;r\u0026#39;) as f: while True: line = f.readline() strline = str(line) m = re.match(\u0026#39;id: GO\u0026#39;,line) if m is not None: if len(father_list) != 0: dict_[term] = father_list father_list = [] term = re.search(\u0026#39;GO:\\d{7}\u0026#39;,line).group() else: h = re.match(\u0026#39;is_a: GO|relationship: part_of\u0026#39;,strline) if h is not None: father = re.search(\u0026#39;GO:\\d{7}\u0026#39;,line).group() father_list.append(father) if not line: break f.close() #迭代找爹 def finder(a): global num father = dict_.get(a) if father: father_list.extend(father) num = num + 1 for i in father: finder(i) else: num_list.append(num) num = 0 #构建字典 dict_ ={} dictGO() tab = pd.read_csv(\u0026#39;1.csv\u0026#39;) #读入1.obo数据，可以将之换成csv读入，反正能读成数据框就行 with open(\u0026#34;dict.csv\u0026#34;,\u0026#34;w\u0026#34;,newline=\u0026#39;\u0026#39;) as csvfile: writer = csv.writer(csvfile, delimiter=\u0026#39; \u0026#39;) writer.writerow([\u0026#34;GO_id,\u0026#34;,\u0026#34;father_num,\u0026#34;,\u0026#34;father_generation,\u0026#34;,\u0026#34;father_id\u0026#34;]) #\u0026#34;GO_id,\u0026#34;结尾的逗号作为csv的分隔符 for j in range(0,len(tab[\u0026#39;goAcc\u0026#39;])-1): a = tab[\u0026#39;goAcc\u0026#39;][j] father_list = [] num_list = [] num = 0 finder(a) father_list = sorted(set(father_list),key=father_list.index)#列表去重复 nummax = max(num_list) #这里求了父节点有几代，因为计算方法是深度优先，取了最大值 writer.writerow([tab[\u0026#39;goAcc\u0026#39;][j],\u0026#34;,\u0026#34;,len(father_list),\u0026#34;,\u0026#34;,nummax,\u0026#34;,\u0026#34;,father_list]) csvfile.close() 计算Trichoderma reesei QM6a中每一个GO分别有多少个基因 方便起见，稍微改一改，另外建一个记录下级节点的字典。\ngocleanlist = [] #所有GO的非重复列表 with open(\u0026#39;2_clean.obo\u0026#39;,\u0026#39;r\u0026#39;) as f: while True: line = f.readline() strline = str(line) m = re.match(\u0026#39;id: GO\u0026#39;,line) if m is not None: gocleanlist.append(re.search(\u0026#39;GO:\\d{7}\u0026#39;,line).group()) if not line: break f.close() len(gocleanlist) #找所有儿子 def dictsonGO(): with open(\u0026#39;2_clean.obo\u0026#39;,\u0026#39;r\u0026#39;) as f: while True: line = f.readline() strline = str(line) m = re.match(\u0026#39;id: GO\u0026#39;,line) if m is not None: son_m = re.search(\u0026#39;GO:\\d{7}\u0026#39;,line).group() h = re.match(\u0026#39;is_a: GO|relationship: part_of\u0026#39;,strline) if h is not None: father = re.search(\u0026#39;GO:\\d{7}\u0026#39;,line).group() if father not in dict_son: dict_son[father] = [son_m] else: dict_son[father].append(son_m) if not line: break f.close() def finderson(a): son = dict_son.get(a) if son: son_list.extend(son) for i in son: if i in finished: #找完所有儿子并统计过的GO跳过，相当于剪枝了 pass else: finderson(i) dict_son ={} dictsonGO() #儿子计数 list_ =[] for j in range(0,len(tab[\u0026#39;goAcc\u0026#39;])-1): a = tab[\u0026#39;goAcc\u0026#39;][j] list_.append(a) result = pd.value_counts(list_) #将Trichoderma reesei QM6a里所有基因所在的GO计数，基因数量最高的GO有500+个基因 result_frame = result.to_frame() dict_result ={} #见字典好去索引，比如A是B的父级，B在该字典里，就把键值（基因数量）也给A加上 for i in range(0,len(result)-1): dict_result[result_frame[0].keys()[i]] = result_frame[0][i] 后面就是对所有GO进行计数，想了想，干脆一起把下一问也一起干了。\n即每一个GO中所属的基因显著上调和下调的个数有多少？\ndeg = pd.read_csv(\u0026#39;DEG.txt\u0026#39;,sep=\u0026#39;\\t\u0026#39;, encoding=\u0026#39;utf8\u0026#39;) Down = [] Up = [] #这个也不多，我循环套循环跑了，觉得浑身难受的就直接建字典。 for i in range(0,len(deg[\u0026#39;gene_id\u0026#39;])): for j in range(0,len(tab[\u0026#39;proteinId\u0026#39;])): if deg[\u0026#39;gene_id\u0026#39;][i] == tab[\u0026#39;proteinId\u0026#39;][j]: if deg[\u0026#39;significance\u0026#39;][i] == \u0026#39;DOWN\u0026#39;: Down.append(tab[\u0026#39;goAcc\u0026#39;][j]) if deg[\u0026#39;significance\u0026#39;][i] == \u0026#39;UP\u0026#39;: Up.append(tab[\u0026#39;goAcc\u0026#39;][j]) #列表建字典，主要后面搜索省时间 Down_dict = {} Up_dict = {} for i in Down: Down_dict[i] = 1 for i in Up: Up_dict[i] = 1 with open(\u0026#34;count_all.csv\u0026#34;,\u0026#34;w\u0026#34;,newline=\u0026#39;\u0026#39;) as csvfile: writer = csv.writer(csvfile, delimiter=\u0026#39; \u0026#39;) writer.writerow([\u0026#34;GO_id,\u0026#34;,\u0026#34;direct_Gene_number,\u0026#34;,\u0026#34;all_of_gene,\u0026#34;,\u0026#34;Down,\u0026#34;,\u0026#34;Up\u0026#34;]) #direct_Gene_number是直属于这个GO的基因，all_of_gene额外加上了下级GO的基因数量。 finished = [] # finderson 找完的记录在里面 finish_down={} # 顺便把down finish_up={} time =0 for a in gocleanlist: #可以加个输出计量运行到哪儿了 son_list = [] Down_num = 0 Up_num=0 n = dict_result.get(a,0) all_of_gene = n finderson(a) son_list = sorted(set(son_list),key=son_list.index) for z in son_list: all_of_gene = all_of_gene + dict_result.get(z,0) if z in Down_dict: if z in finish_down: Down_num = Down_num + finish_down[z] else: Down_num =Down_num+1 if z in Up_dict: if z in finish_up: Up_num = Up_num + finish_up[z] else: Up_num =Up_num+1 if all_of_gene == 0: #没有就不记了，省地方，不然得一堆0中找值 pass else: writer.writerow([a,\u0026#34;,\u0026#34;,n,\u0026#34;,\u0026#34;,all_of_gene,\u0026#34;,\u0026#34;,Down_num,\u0026#34;,\u0026#34;,Up_num]) finished.append(a) finish_down[a]=Down_num finish_up[a]=Up_num csvfile.close() #输出便是此番结果 GO_id, direct_Gene_number, all_of_gene, Down, Up GO:0000002 , 1 , 1 , 0 , 0 GO:0000003 , 0 , 1 , 0 , 0 GO:0000009 , 15 , 15 , 0 , 0 GO:0000015 , 2 , 2 , 0 , 0 GO:0000026 , 15 , 18 , 1 , 0 GO:0000030 , 19 , 104 , 5 , 0 GO:0000033 , 15 , 15 , 0 , 0 GO:0000036 , 3 , 3 , 0 , 0 GO:0000041 , 0 , 8 , 0 , 1 GO:0000049 , 1 , 1 , 0 , 0 GO:0000059 , 10 , 10 , 0 , 0 GO:0000062 , 2 , 2 , 0 , 0 GO:0000087 , 1 , 1 , 0 , 0 GO:0000096 , 0 , 11 , 0 , 0 GO:0000097 , 0 , 8 , 0 , 0 GO:0000103 , 2 , 3 , 0 , 0 GO:0000104 , 3 , 6 , 0 , 0 GO:0000105 , 7 , 7 , 0 , 0 GO:0000107 , 2 , 2 , 0 , 0 GO:0000121 , 1 , 1 , 0 , 0 GO:0000139 , 3 , 3 , 0 , 0 GO:0000140 , 8 , 8 , 0 , 0 GO:0000145 , 3 , 3 , 0 , 0 GO:0000148 , 2 , 2 , 0 , 0 GO:0000150 , 1 , 1 , 0 , 0 GO:0000151 , 56 , 58 , 0 , 0 ...... 哪些GO发生了显著的上调或者下调的富集？ 做GO的富集是算超几何分布，相比python，使用R更简单。\nlibrary(dplyr) setwd(\u0026#34;C:/Users/syddd/bioinfomation\u0026#34;) cou \u0026lt;- read.csv(\u0026#34;count_all.csv\u0026#34;) N = 13267+3043+2410 # 三个顶级GO的基因数量相加 n_down = 150 + 22 + 9 n_up = 222 + 32 + 16 df1\u0026lt;-data.frame(GO_id=c(), down_p_value=c(), up_p_value=c()) df2\u0026lt;-data.frame(GO_id=c(), down_p_value=c()) df3\u0026lt;-data.frame(GO_id=c(), up_p_value=c()) for (i in 1:nrow(cou)) { k_down \u0026lt;- cou[i,\u0026#34;Down\u0026#34;] k_up \u0026lt;- cou[i,\u0026#34;Up\u0026#34;] m \u0026lt;- cou[i,\u0026#34;all_of_gene\u0026#34;] p_down = 1-phyper(k_down-1,m, N-m, n_down) p_up = 1-phyper(k_up-1,m, N-m, n_up) list1 \u0026lt;- list(GO_id=cou[i,\u0026#34;GO_id\u0026#34;], down_p_value=p_down, up_p_value=p_up) df1 \u0026lt;- rbind(df1,as.data.frame(list1)) if (p_down \u0026lt;= 0.05){ #挑出来下调显著的 list2 \u0026lt;- list(GO_id=cou[i,\u0026#34;GO_id\u0026#34;], down_p_value=p_down) df2 \u0026lt;- rbind(df2,as.data.frame(list2)) } if (p_up \u0026lt;= 0.05){ #挑出来上调显著的 list3 \u0026lt;- list(GO_id=cou[i,\u0026#34;GO_id\u0026#34;], up_p_value=p_up) df3 \u0026lt;- rbind(df3,as.data.frame(list3)) } } ","date":"2021-06-11T20:11:25+08:00","image":"https://s2.loli.net/2021/12/03/obycVOJlgKFZpjA.png","permalink":"https://deathsprout.gitee.io/p/%E5%B1%B1%E4%B8%9C%E5%A4%A7%E5%AD%A6%E7%94%9F%E7%89%A9%E4%BF%A1%E6%81%AF%E5%AD%A6%E5%AE%9E%E9%AA%8C-%E8%BD%AC%E5%BD%95%E7%BB%84%E5%AD%A6%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%92%8C%E5%AF%8C%E9%9B%86%E5%88%86%E6%9E%90/","title":"山东大学生物信息学实验 - 转录组学数据分析和富集分析"},{"content":"常见定年软件\n 最大似然法：  r8s Reltime   贝叶斯法：  PAML-MCMCTree（PAML4软件包内含） 其他（Timetree）    这里是mcmctree的手册\n事先声明，mcmctree使用氨基酸序列进行定年比使用核酸序列麻烦的多，而且在此之前，能找到帖子的都语焉不详，手册里的Tutorial 4是主要参考，可以先跑一遍示例文件，坑主要是体现在文件格式上。\n若使用氨基酸序列来进行分析，由于mcmctree不能选择较好的氨基酸替换模型进行分析，需要自己手动运行codeml进行分析后，在生成中间文件用于运行mcmctree。若非是因为数据原因必须用氨基酸序列进行定年，还是推荐使用核酸序列。\n前置 需求文件：(后面称其为那三个文件)\n 多序列比对文件 带有校准信息有根树 控制文件 mcmctree.ctl  前两个文件的格式很重要，参考examples里的abglobin.aa 和 abglobin.trees\n \n \n树文件一定保证有至少一个时间校正点，\u0026lsquo;B(1.7,1.9)\u0026lsquo;的意思是最外面的这个分支点的时间，经化石证据矫正约束在170Mya到190Mya1年之间。\n多序列对比文件第一行是： 序列数 序列长 （大写的）i 下面每行是一个序列名，和后面序列对应，序列名与序列之间的有空行，数字则是表明其下的序列们第一个位置是第几位。\n我将fasta文件转变为phylip后，如下图所示，序列名并没有单独成行，它的格式并不能直接用，会报错。我也没找到合适的现有格式能方便的转换过去。 我参考的其他博客都是将其转化为phylip就能正常使用，唯一的区别是他们使用核酸序列而我用的是氨基酸序列，这是我踩的坑。\n \n数字不要紧，我在第一行后面加了个I后，除了第一行以外都能识别出，下面是识别过程的输出。  \n所以重点是将\nG000238395 IVDLIDKVGL KDYQACCPFH NEKSPSFTVS QDKYHCFGCG ANGNAISFVM\nG000263075 IVDLIDKVGL KDYQACCPFH NEKSPSFTVS QDKYHCFGCG ANGNAISFVM\n这种形式变成下面那种形式\nG000238395\nG000263075\n（空行）\nIVDLIDKVGL KDYQACCPFH NEKSPSFTVS QDKYHCFGCG ANGNAISFVM\nIVDLIDKVGL KDYQACCPFH NEKSPSFTVS QDKYHCFGCG ANGNAISFVM\n数量大的话可以写个脚本，这里数量不多，用excel分割剪切出来，替换Tab键为空格再复制进去。\n流程 首先把那三个文件放在一个目录里，修改mcmctree文件，如下图红色部分所示。\n \nseqfile # 多序列比对文件\rtreefile # 带有校准信息有根树\rndata # 输入的多序列比对的数据个数，是密码子就是3；否则设置为1\rseqtype = 2 * 0: nucleotides; 1:codons; 2:AAs #数据类型(2为氨基酸)\rusedata = 1 * 0: no data; 1:seq like; 2:normal approximation; 3:out.BV (in.BV) # 设置是否利用多序列比对的数据：\\\r#0，表示不使用多序列比对数据，则不会进行likelihood计算，虽然能得到mcmc树且计算速度飞快，但是其分歧时间结果是有问题的；\\\r#1，表示使用多序列比对数据进行likelihood计算，正常进行MCMC，是一般使用的参数; \\\r#2，进行正常的approximation likelihood分析，此时不需要读取多序列比对数据，直接读取当前目录中的in.BV文件。该文件是使用usedata = 3参数生成的out.BV文件重命名而来的。\\\r#此外，由于程序BUG，当设置usedata = 2时，一定要在改行参数后加 *，否则程序报错 Error: file name empty.. \\\r#3，程序利用多序列比对数据调用baseml/codeml命令对数据进行分析，生成out.BV文件。由于mcmctree调用baseml/codeml进行计算的参数设置可能不太好（特别时对蛋白序列进行计算时），\\\r#推荐自己修改软件自动生成的baseml/codeml配置文件，然后再手动运行baseml/codeml命令，再整合其结果文件为out.BV文件。\r运行\nmcmctree mcmctree.ctl\r之后会生成一系列文件，删除out.BV和rst文件，将wag.dat拷贝进来， (wag.dat在paml dat 目录里，我是在..pamlX\\paml4.9j\\dat\\ 里面)\n打开文件tmp0001.ctl，全部替换为下列内容。\nseqfile = tmp0001.txt\rtreefile = tmp0001.trees\routfile = tmp0001.out\rnoisy = 3\rseqtype = 2\rmodel = 2 * 2: Empirical\raaRatefile = wag.dat\rfix_alpha = 0\ralpha = .5\rncatG = 4\rSmall_Diff = 0.1e-6\rgetSE = 2\rmethod = 1\r运行\ncodeml tmp0001.ctl\r这样就使用WAG+Gamma生成了适当的Hessian矩阵，接下来将rst2重命名为in.BV,现在可以更改mcmctree.ctl 的 usedata = 2\n回到上一目录，新建一个文件夹，将 那三个文件和新生成的in.BV拷贝进去\n接下来运行\nmcmctree mcmctree.ctl\r后续与mcmctree无关\n参考  MCMCTree tutorials mcmctree估算物种分歧时间 使用PAML进行分歧时间计算    Mya:百万年,mcmctree的单位是100个百万年\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   ","date":"2021-05-25T06:52:23+08:00","permalink":"https://deathsprout.gitee.io/p/mcmctree-%E5%AE%9A%E5%B9%B4-%E4%BD%BF%E7%94%A8%E6%B0%A8%E5%9F%BA%E9%85%B8%E5%BA%8F%E5%88%97/","title":"mcmctree 定年 —— 使用氨基酸序列"},{"content":"chaotica 这个软件是我在一年前发现，那时候正满怀热情的学习Blender，在那之前还兴致勃勃的修完了许德民教授讲关于抽象艺术的尔雅网课。\n老师关于抽象艺术的讲解很大程度上改变了我对该类艺术作品的看法，说是醍醐灌顶也不为过（惭愧的是当时是第一次修习尔雅网课，忘记了最后的考试）。\n许德民教授很鼓励学生自己去创作抽象作品，也不要将其看的过高过于艰深遥远，他们课程的最后作业便是创做几幅抽象画了，我很是眼馋，然后用PS（上）和SAI 2（下）画了两幅抽象画。\n \n这张我很是满意，倒不是有什么寓意，有意思而且看着舒服罢了。\n \n（裁剪）本是像弄出影印版书封皮的质感的，灵感来源兴许是格林伍德元素化学。\n说了些无关的，介绍下本文的正主chaotica。 Chaotica是一款新一代分形艺术应用程序，新手用户可以享受编辑随机分形产生的惊人高清壁纸和动画。下面是他们的官方网站\n \nbilibili上有较为详细的入门教程，看完感兴趣可以去学学。\nhttps://www.bilibili.com/video/BV12f4y1X7JD/?spm_id_from=333.788.recommend_more_video.-1\n作品分享 我用chaotica制作了些图片，过程中偶尔出现惊喜，虽然没有chaotica里那些专业艺术家做的那么棒，但还是挺酷的，在这里分享给大家。\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n","date":"2021-05-24T16:09:47+08:00","image":"https://i.loli.net/2021/05/24/nQovGt7zCABKLXZ.png","permalink":"https://deathsprout.gitee.io/p/%E5%88%86%E5%BD%A2%E8%89%BA%E6%9C%AF-chaotica%E4%BD%9C%E5%93%81/","title":"分形艺术 Chaotica作品"},{"content":"关于笔记难免会选择性记忆，自己已然掌握的便不会记录，比如perl的正则表达式和python共通，便不记录在里面。（当然在这里更推荐去学python）\nsort #对数组排序（默认按照字符串排序） reverse #列表反向排列 sort{$a cmp $b}; #（由小到大） sort{$b cmp $a}; #（由大到小） sort{$a \u0026lt;=\u0026gt; $b}; #(按照数值进行排序) sort {$h{$a}\u0026lt;=\u0026gt;$h{$b}} key %h; #对哈希 比value排key # 用 . 可以将字符串连接 substr $总串,开始位置,长度,该内容替换被取出的内容;#用来取子串 index $字符串,\u0026#34;寻找的内容\u0026#34;,起始位置;#搜寻字符串内容，返回位置 my $str = \u0026#34;xal\u0026#34; x 5; #输出xalxalxalxalxal join \u0026#34;自定分隔符\u0026#34;,@arr; #连接数组中所有的字符串 split /自定分割符/,$str; #分割字符串 2021/04/28\n#! /usr/bin/perl use strict; use warnings; my @lines; #数组的每一项对应文件的每一行 my $tmp; #依次把每一行赋值给临时变量 open IN,\u0026#34;testout.txt\u0026#34; or die \u0026#34;fail to open testout.txt to read:$!\\n\u0026#34;; while ($tmp = \u0026lt;IN\u0026gt;) { chomp $tmp; #把字符串尾巴的换行符切掉 print\u0026#34;line:|\u0026#34;,$tmp,\u0026#34;|\\n\u0026#34;; } while (\u0026lt;IN\u0026gt;) { #因为上一个while以及把指针指到文件末尾了，此while将没有输出 print\u0026#34;line:|\u0026#34;,$_,\u0026#34;|\\n\u0026#34;;#临时变量 } close IN; open IN,\u0026#34;testout.txt\u0026#34; or die \u0026#34;fail to open testout.txt to read:$!\\n\u0026#34;; while (\u0026lt;IN\u0026gt;) { chomp $_; print\u0026#34;line:|\u0026#34;,$_,\u0026#34;|\\n\u0026#34;;#临时变量 } close IN; open OUT,\u0026#34;\u0026gt;testout.txt\u0026#34; or die \u0026#34;fail to open testout.txt to write:$!\u0026#34;;# $!是存放最近的出错信息的变量 print OUT \u0026#34;this is the 1 line.\\n\u0026#34;; print OUT \u0026#34;this is the 2 line.\\n\u0026#34;; close OUT; my @arr = (\u0026#34;list\u0026#34;); $arr[$#arr+1] = \u0026#34;new\u0026#34;;#尾添 push @arr,\u0026#34;new_push\u0026#34;;#尾添 print \u0026#34;@arr\\n\u0026#34;; pop @arr;#尾删 print \u0026#34;@arr\\n\u0026#34;; shift @arr;#头删 print \u0026#34;@arr\\n\u0026#34;; unshift @arr,\u0026#34;interposition\u0026#34;;#头插入 print \u0026#34;@arr\\n\u0026#34;; my $return; $return = shift @arr;# 将@arr的头删除并将其作为返回值赋值给$return print\u0026#34;$return\\n @arr\\n\u0026#34;; # $return = shift; #在运行perl文件时输入数据作为参数 # such as perl input_output.pm 1 2 3 $return = shift @ARGV;# 通过添加@ 使其能添加多个参数 if (not $return){ die \u0026#34;usage:perl arg.plx\u0026lt;paramter\u0026gt;\\n\u0026#34;; }#没给参数，杀死并报错 print\u0026#34;$return\\n @arr\\n\u0026#34;; # 使得脚本可以接受文件名作为参数，打开该文件并逐行输出 my $filename; $filename = shift; if (not $filename){die \u0026#34;usage:perl arg.plx\u0026lt;paramter\u0026gt;\\n\u0026#34;;} open IN,$filename or die \u0026#34;fail to open $filename to write:$!\u0026#34;; while (\u0026lt;IN\u0026gt;) { chomp $_; print $_,\u0026#34;\\n\u0026#34;; } close IN; 读取fasta文件，读取并输出序列信息和序列本身。\n#! /usr/bin/perl use strict; use warnings; my $filename; my @seq = ();my @name = (); my $cnt = 0; my $lnbuf ;my $ch ; my $tmpname;my$tmpseq; $filename = shift; if (not $filename){die \u0026#34;usage:perl arg.plx\u0026lt;paramter\u0026gt;\\n\u0026#34;;} open IN,$filename or die \u0026#34;fail to open $filename to write:$!\u0026#34;; while (\u0026lt;IN\u0026gt;) { chomp; $ch = substr $_,0,1; if ($ch eq \u0026#34;\u0026gt;\u0026#34;){ if ($cnt == 0){ $tmpname = $_; # push @name,$_; $cnt ++; } else{ push @name,$tmpname; push @seq,$tmpseq; $tmpseq = \u0026#34;\u0026#34;; $cnt ++; $tmpname=$_;} } else { $tmpseq .= $_; # 连接缩写 .= # @seq[$cnt-1] .= $_; } } close IN; if($tmpname ne \u0026#34;\u0026#34;){ push @name,$tmpname; push @seq,$tmpseq; } foreach my $i(0 .. $#name){ print $name[$i],\u0026#34;\\n\u0026#34;,$seq[$i],\u0026#34;\\n\u0026#34;; } Perl的正则表达式的三种形式，分别是匹配，替换和转化:\n  匹配：m//（还可以简写为//，略去m）\n  替换：s///\n  转化：tr///\n  这三种形式一般都和 =~ 或 !~ 搭配使用， =~ 表示相匹配，!~ 表示不匹配。\nperl处理完后会给匹配到的值存在三个特殊变量名:\n  $`: 匹配部分的前一部分字符串\n  $\u0026amp;: 匹配的字符串\n  $': 还没有匹配的剩余字符串\n  my $str = \u0026#34;Hello the perl world\u0026#34;; $str =~/Hello/; #搜索 搜到返回为真 $str =~/Hello/ ? print \u0026#34;found Hello\\n\u0026#34; : print \u0026#34;can\u0026#39;t found\\n\u0026#34; ; my $str2 = \u0026#34;\u0026gt;seq1 \u0026gt;seq2 \u0026gt;seq3\u0026#34;; $str2 =~/^\u0026gt;/ ? print \u0026#34;found \u0026gt; at begin\\n\u0026#34; : last ; # ^ 锚定到句首 # $ 锚定到句末， bp$ 搜索句末的bp my $str3 = \u0026#34;total length 10000000 bp, N50 20000 bp\u0026#34;; $str3 =~/total length (\\d{1,}) bp/ ? my $tot_len = $1 : last ; print $tot_len,\u0026#34;\\n\u0026#34;; # () 里面的值会被抓取出来，存在临时变量里 第一个放在 $1,第二个放在 $2 ... # \\d 匹配任何Unicode十进制数（就是在Unicode字符目录[Nd]里的字符） ## 这包括了 [0-9] ，和很多其他的数字字符。如果设置了 ASCII 标志，就只匹配 [0-9]  # {1,} 表示匹配次数，1次以上 my $str4 = \u0026#34;joadfffff the\u0026#34;; $str4 =~/(f*)\\s*(the)/ ? my $jiaf = $1.$2 : last ; print $jiaf,\u0026#34;\\n\u0026#34;; # \\s 匹配任何Unicode空白字符（包括 [\\t\\n\\r\\f\\v]) # *? \u0026#39;*\u0026#39;, \u0026#39;+\u0026#39;，和 \u0026#39;?\u0026#39; 修饰符都是贪婪的,在后面加？，表示非贪婪匹配 my $str5 = \u0026#34;01234569acespvnmgogjbtfgg\u0026#34;; $str5 =~/([0-9a-h]+)/ ? print $1,\u0026#34;\\n\u0026#34; : last ; $str5 =~/([^0-9a-h]+)/ ? print $1,\u0026#34;\\n\u0026#34; : last ; # [^ ]表示反选字符集合 my $string = \u0026#39;4runoooob2,57\u0026#39;; $string =~ tr/a-z/A-Z/s ; print \u0026#34;$string\\n\u0026#34;; # s把多个相同的输出字符缩成一个 $string =~ tr/N/ /c ; print \u0026#34;$string\\n\u0026#34;; # 把所有非N 替换为空格 $string =~ tr/\\t //d ; print \u0026#34;$string\\n\u0026#34;; # 删除tab和空格 $string =~ tr/0-9/ /cs ; print \u0026#34;$string\\n\u0026#34;; # 把数字间的其它字符替换为一个空格。 引用：用来弄高维数据结构（实际是指针）\nmy $addr = \\$str ; print $addr,\u0026#34;\\t\u0026#34;,$$addr,\u0026#34;\\n\u0026#34;; # \\$str 取地址，| ${ $addr } 解引用，也可缩写为 $$addr #输出： SCALAR(0x7fffc0a84060) Hello the perl world my @arr = (1 .. 7); my $addr2 = \\@arr ; print $addr2,\u0026#34;\\t\u0026#34;,\u0026#34;@{ $addr2 }\u0026#34;,\u0026#34;\\t\u0026#34;,${ $addr2 }[0],\u0026#34;\\n\u0026#34;; # ARRAY(0x7ffff5b228c8) 1 2 3 4 5 6 7 1 my %h = (a=\u0026gt;1,b=\u0026gt;2,c=\u0026gt;3); my $addr3 = \\%h; print $addr3,\u0026#34;\\t\u0026#34;,keys %{$addr3},\u0026#34;\\n\u0026#34;; print ref($addr),\u0026#34;\\t\u0026#34;,ref($addr2),\u0026#34;\\t\u0026#34;,ref($addr3); # ref() 返回引用的类型 # HASH(0x7fffdae689e8) cab my @arrac1 = split / +/,\u0026#34;4 -1 -4 0 1\u0026#34;; my @arrac2 = split / +/,\u0026#34;2 -3 -4 0 1\u0026#34;; my @arrac3 = split / +/,\u0026#34;1 -5 -4 0 1\u0026#34;; my @arr_of_arr ; $arr_of_arr[0]= \\@arrac1;$arr_of_arr[1]= \\@arrac2;$arr_of_arr[2]= \\@arrac3; foreach my $i (0 .. $#arr_of_arr){ print $i,\u0026#34;\\t\u0026#34;,$arr_of_arr[$i],\u0026#34;\\t\u0026#34;,\u0026#34;@{$arr_of_arr[$i]}\u0026#34;,\u0026#34;\\n\u0026#34;; }# 演示，非实际用法，麻烦的写法 @{ $arr_of_arr[0] } = split / +/,\u0026#34;1 2 3 4 5\u0026#34;; # 省事操作 foreach my $i (0 .. $#arr_of_arr){ print $i,\u0026#34;:\u0026#34;; foreach my $j (0 .. $#{$arr_of_arr[$i]}){ print \u0026#34; \u0026#34;,$j,\u0026#34;(\u0026#34;,$arr_of_arr[$i][$j],\u0026#34;)\u0026#34;; } print \u0026#34;\\n\u0026#34;; } # can $arr_of_arr[$i] -\u0026gt; [$j] my $arrlist = [ [9,8,7,6,5], [1,2,3,4,5], [5,5,5,5,5], ]; #匿名数组 print @$arrlist,\u0026#34;\\t\u0026#34;,\u0026#34;@{@$arrlist[0]}\u0026#34;;   上图是部分输出结果\n# 计算拼接成contig的文件 N50的perl程序 use strict; use warnings; my @name;my @seq;my $seq; my @long ; my $alllong = \u0026#34;\u0026#34;; my $contig = 0 ; my $longest; my $shortest; my $GC=0 ; my $N=0; my $N50; open IN,\u0026#34;data/a9_k63.contig.long1500\u0026#34; or die \u0026#34;$!\u0026#34;; # a9_k63.contig.long1500 while (\u0026lt;IN\u0026gt;) { chomp; my $head = substr $_,0,1; if ($head eq \u0026#34;\u0026gt;\u0026#34;){ if ($contig == 0){ $contig ++; push @name,$_; } else{ $contig ++; push @name,$_; $alllong .= $seq ; push @seq,$seq; push @long,length($seq); $seq = \u0026#34;\u0026#34;; } } else{ $seq .= $_; } } push @seq,$seq; $alllong .= $seq ; push @long,length($seq); close IN; my @arrlong = sort{$a\u0026lt;=\u0026gt;$b} @long; $longest = $arrlong[0];$shortest = $arrlong[$#long]; my $G = $alllong =~ tr/G/G/; my $C = $alllong =~ tr/C/C/; $N = $alllong =~ tr/N/N/; $GC = ($G+$C)/length($alllong); my $sum =0;my $lo2 = length($alllong)/2; foreach my $i (0 .. $#arrlong){ $sum = $sum+$arrlong[$i]; if ($sum \u0026gt; $lo2){ $N50 = $arrlong[$i]; last; } } print \u0026#34;@long\\n\u0026#34;; print \u0026#34;大小：\u0026#34;,length($alllong),\u0026#34;\\tcontig数:\u0026#34;,$contig,\u0026#34;\\n\u0026#34;; print \u0026#34;最短contig：\u0026#34;,$longest,\u0026#34;\\t最长contig:\u0026#34;,$shortest,\u0026#34;\\n\u0026#34;; print \u0026#34;GC含量:\u0026#34;,$GC,\u0026#34;\\t\\tN数量:\u0026#34;,$N,\u0026#34;\\n\u0026#34;; print \u0026#34;N50:\u0026#34;,$N50,\u0026#34;\\n\u0026#34;; ","date":"2021-05-22T19:35:28+08:00","image":"https://i.loli.net/2021/12/03/b5iCUtcZKnwF1BJ.jpg","permalink":"https://deathsprout.gitee.io/p/perl%E5%AE%9E%E9%AA%8C%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/","title":"Perl实验课程笔记"},{"content":"系统：Ubuntu 20.0.4\n轮子：ena-fast-download\n环境需求：\n An Aspera connect client (see https://www.ibm.com/aspera/connect/ or https://www.biostars.org/p/325010/) curl(Linux自带，但版本不要太旧) Python 3  Aspera 配置 在 https://www.ibm.com/aspera/connect/下载合适的IBM Aspera Connect。解压结束在shell运行那个.sh文件，安装IBM Aspera Connect。\n配置$PATH,手动配置是在/home/user（用户名,我的是sprout）位置的.bashrc文件最后添加\nexport PATH=/home/sprout/.aspera/connect/bin:$PATH asperaweb_id_dsa.putty 和asperaweb_id_dsa.openssh是密匙文件，要在最后ascp使用时用到，在后面加 -i 密匙文件的位置，正常使用ascp是如果putty不能用就用openssh，这个脚本ena-fast-download用的密匙是openssh，所以环境变量也要加上。\nexport PATH=/home/sprout/.aspera/connect/etc/asperaweb_id_dsa.openssh:$PATH 使用 Linux下是将ena-fast-download这里面的python脚本放到想下数据的文件夹中，执行下面的命令。\n./ena-fast-download.py ERR1701760 实际上这个脚本是用ERR1701760得到完整的路径去使用ascp，比如上面这个最终会生成(其中一个，双端测序数据，还一个2)\nascp-T-1 300m -P33001-i $HOME/.aspera/connect/etc/asperaweb_id_dsa.openssh era-fasp@fasp.sra.ebi.ac.uk:/vol1/fastq/ERR1701/000/ERR1701760/ ERR1701760 1.fastq.gz . 问题 我一开始使用下着下着会中断，不清楚是什么问题，可能是Ubuntu长时间不动熄屏导致，也可能是流程里有什么东西变了导致现在用不了。 单纯的运行ascp脚本报错如下：\nSession Stop (Error:Session data transfer timeout(server),Session data transfer timeout) 后来发现是实验室网络问题，在宿舍运行速度可以达到60MB/s。\n","date":"2021-05-22T13:23:33+08:00","permalink":"https://deathsprout.gitee.io/p/%E4%BB%8Eena%E9%AB%98%E9%80%9F%E4%B8%8B%E8%BD%BDfastq%E6%96%87%E4%BB%B6/","title":"从ENA高速下载FASTQ文件"},{"content":"同样发表在知乎上\n为什么写这篇文章？ 这是我在为完成《蛋白质工程》课程展示任务过程中写的，选题自然是cas蛋白，我发现在网络和各类博客上反而很难找到cas9蛋白的具体内容，它被介绍CRISPR-Cas的文章淹没了，在读了十几篇文献后，用latex写了笔记。鉴于关于CRISPR-Cas的内容随处可见，完全可以去看产品手册或者其他什么，这篇文章中删去了与Cas蛋白无直接关系的大量内容。\nCas蛋白简介 Cas是CRISPR相关蛋白的简称， 簇状规则间隔的短回文重复序列（CRISPR）和相关蛋白（Cas）构成CRISPR–Cas系统1，是许多细菌和大多数古细菌中存在的抗噬菌体免疫系统。 近年来，CRISPR–Cas系统已发展成为可靠而强大的基因组编辑工具。\n CRISPR系统的三大类和十个子类的关系  上图1表示有三大类的CRISPR系统（I、II、III），而又可以细分为十个子类，可以看出在CRISPR系统中含有很多种类的Cas蛋白，Cas1到Cas10以及如Cas8a1、Cas12a、Cas13a等比较稀少的类型。2\n第2类CRISPR-Cas系统的特征是由单一、大、多结构域的蛋白质组成复合体发挥作用，一些2类效应蛋白，如Cas9,已经成功地用于基因组工程。3\n 基于不同的效应蛋白家族,CRISPR II类系统又可细分为3类、9亚型 \n 不同种类的Cas蛋白数量分布  上图3则是CasPDB数据库统计的在不同种类的菌体中所含的Cas蛋白数量分布，在统计的所有 Cas 蛋白中，Cas1占20.11% ，cas2占17.46% ，Cas3、 Cas5和 Cas6占10% 以上。其余的较少，最著名的Cas9蛋白则在所有Cas蛋白中占2.59%，本文也将重点讨论Cas9蛋白。\nCas9蛋白结构 Cas9蛋白立体结构   SpCas9 -ABE8e 结构, 是使用PyMOL将从PDB数据库中获取的Cas9结构简单的可视化后的图像。4\n  3.2 A分辨率下的SpCas9-ABE8e复合物的冷冻电镜建模结构, SpCas9-ABE8e 冷冻电镜结构：SpCas9灰色显示； sgRNA紫色； 靶链DNA蓝绿色； 非靶链DNA蓝色； TadA-8e二聚体红色和粉红色显示。 Cas9 N端与TadA-8e C端之间的直线距离显示为橙色虚线。\nCas9蛋白结构域   Cas9蛋白结构域分为REC结构域、Ruvc结构域、HNH结构域、PI结构域,图6还特地将富含精氨酸的alpha螺旋用紫色标示出来。其中REC结构域可以分为REC1-A、REC2、REC1-B、REC3，作用是连接其他结构域。Ruvc结构域分为三个结构域，彼此之间并不靠近。\n  a是靶链DNA和sgRNA结合示意图。b是sgRNA-靶链DNA连接的正交视图。c是Cas9–sgRNA–DNA复合体的前视图和后视图。 在上图7中，RNA均为橙色，靶链DNA为浅蓝色，非靶链DNA为黑色。 非靶链中的5'-NGG-3\u0026rsquo;PAM三核苷酸以黄色突出显示。图中蛋白质上不同的颜色显示了不同的结构域。5\nCas9蛋白功能及作用机制 Cas9蛋白在CRISPR-Cas系统中的功能 上图8显示的是Type II 系统的作用过程。3 首先是依靠Cas1、2复合体将原间隔序列的片段制作成间隔序列整合进CRISPR序列中，形成对外源DNA的记忆，然后在接下来的免疫中，间隔序列就能快速产生原间隔序列片段，这些序列片段与Cas9一起靶向地切除在细菌内的外源DNA，PAM在这里参与防止自身免疫疾病的机制，保障不会切除自身DNA。\nCas9蛋白功能的机制 结合DNA并识别目标序列   上图是SpCas9寻找目标位点的步骤示意图，apo-Cas9 与DNA相互作用靠的是随机碰撞，结合后很快分开。在apo-Cas9 与sgRNA 结合后形成Cas9 RNP，使SpCas9发生形态和功能改变，允许目标通过沿双链DNA 的进行单向搜索约27个bp（非靶链DNA-3\u0026rsquo;至5'），除非遇到PAM，否则就快速的与DNA分离。与 PAM 的稳定相互作用则促使互补底物上稳定R环的形成，从而激活 Cas9以进行 DNA 切割。6\n就这样借助sgRNA的部分序列与靶DNA位点进行碱基配对，能够引导Cas9结合到这个靶位点上并进行切割。II型和V-B型系统需要tracrRNA才能正常发挥功能，而V-A型系统则需要单独使用crRNA 。在实际应用时，人们可以将tracrRNA和crRNA作为两种向导RNA（gRNA）或者融合在一起形成单向导RNA（single guide RNA, sgRNA），后一种方式已经广泛用于Cas9引导酶Cas9结合到靶DNA序列上并进行切割，Cas9与sgRNA一起被称作Cas9-sgRNA系统。\n  a.Cas9中PAM结合区的放大视图。b.Cas9与PAM相互作用示意图,红圈表示桥接水分子。c.主要凹槽的详细视图。 与GG-PAM的特异性氢键相互作用用虚线表示。 非靶链中的 dG2 * 和 dG3 * 的鸟嘌呤核酸碱基在主槽中分别被 arg1333和 arg1335的碱基特异性氢键相互作用读出， 这些氢键来自 Cas9 C末端的 $\\beta$发夹，而与PAM互补的靶链核苷酸不被主沟槽相互作用识别。与PAM相互作用的精氨酸残基在Cas9序列中是保守的。7\n \n残基Glu 1108和ser 1109与靶DNA链中的+1磷酸二酯基团相互作用，直接导致PAM上游的局部链分离，将靶链转为与sgRNA结合（1-2bp），靶链DNA与sgRNA之间的碱基配对促进了引导-靶标异质双链的进一步逐步置换和传播。7\n切割 Cas9的基因组编辑能力只有在被称作前间隔序列邻近基序(protospacer adjacent motif, PAM)的短片段DNA序列的存在下才成为可能。只有DNA靶位点附近存在PAM时，Cas9才能进行准确切割。PAM的存在也是激活酶Cas9所必需的，PAM 序列的特征为 NGG（其中 N 为任意核苷酸）。8\n核酸酶Cas9含有两个具有切割活性的结构域：HNH结构域和RuvC结构域，其中 HNH结构域切割与crRNA互补的DNA链，而RuvC结构域切割非互补链(即HNH和 RuvC结构域协同切割TS和NTS)。RuvC结构域可分为三个亚结构域：RuvC I、RuvC II和RuvC III，RuvC I接近于Cas9的氨基端，RuvC II和RuvC III位于HNH结构域的两侧（见图5）。9\n当Cas9与靶基因位点结合时发生了构象变化，核酸酶功能区对靶标DNA的反向链进行定位切割。Cas9介导的DNA切割最后结果是目标DNA（PAM序列上游约 3～4个核苷酸）的双链断裂（double strand break，DSB）。   上图是切割位置示意图，实验中观察到的切割位点由黑色（HNH）和蓝色（RuvC）三角形标记（蓝色填充:首选位点，无填充:典型位点(较不利)，青色填充:不利位点）。10\n传统的Cas9蛋白包含RuvC和HNH两个催化结构， RuvC和HNH可分别剪切DNA的两条链形成双链断裂，如gRNA与非目标区域结合就有造成不必要插入突变的可能。\n其他 存在的问题 基因组极为复杂，gRNA可能与非靶向序列局部匹配，这种局部匹配也会激活Cas 9内切酶活性，从而产生脱靶效应。11\n此外，Cas9不仅识别标准PAM，也可识别非标准PAM，这也可能会引起一定程度的脱靶。脱靶可能影响正常基因的功能表达，甚至激活致癌因子、抑制抑癌基因，造成安全隐患，这极大的阻碍了该技术在临床的进一步应用。目前主要通过优化gRNA 设计，改造Cas9蛋白，使用RNP递送方式等策略来提高CRISPR/Cas9系统特异性以降低脱靶现象。\nCas9蛋白突变体 博德研究所的研究人员对Cas9进行突变使RuvC和HNH两个催化结构域中的一个缺失核酸酶活性形成Cas9n，Cas9n与DNA双链作用时仅产生单链切口。应用CRISPR/Cas9n系统进行基因编辑需要使用两个相邻且相反链上的gRNA序列。虽然所用的每条gRNA的脱靶结合位点可能出现在全基因组范围内，但是Cas9n仅催化每个位置的单链断裂 （Single-strand break，SSB）。SSB优先通过HDR进行修复，而不是NHEJ，这可降低不必要的插入缺失突变的发生。应用CRISPR/Cas9n系统进行基因编辑能将脱靶活性降低50-1000倍。12\n  本文不介绍与Cas蛋白无关的CRISPR–Cas技术细节，有兴趣的详见 CRISPR Guide\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n Makarova K S , Haft D H , Barrangou R , et al. Evolution and classification of the CRISPR–Cas systems[J]. Nature Reviews Microbiology.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n Makarova K S , Zhang F , Koonin E V . SnapShot: Class 2 CRISPR-Cas Systems[J]. Cell, 2017, 168(1-2):328-328.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n DOI: 10.2210/pdb6VPC/pdb\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n Anders, Carolin, Niewoehner, et al. Structural basis of PAM-dependent target DNA recognition by the Cas9 endonuclease.[J]. Nature, 2014.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n Lapinaite A , Knott G J , Palumbo C M , et al. DNA capture by a CRISPR-Cas9–guided adenine base editor[J]. ence, 2020, 369(6503):566-571.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n Anders, Carolin, Niewoehner, et al. Structural basis of PAM-dependent target DNA recognition by the Cas9 endonuclease.[J]. Nature, 2014.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n Nierzwicki U , Arantes P R , Saha A , et al. Establishing the allosteric mechanism in CRISPR‐Cas9[J]. Wiley Interdiplinary Reviews: Computational Molecular ence.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n Huai C , Li G , Yao R , et al. Structural insights into DNA cleavage activation of CRISPR-Cas9 system[J]. Nature Communications, 2017, 8(1):1375.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n Stephenson A , Raper A T , Suo Z . Bidirectional Degradation of DNA Cleavage Products Catalyzed by CRISPR/Cas9[J]. Journal of the American Chemical Society, 2018, 140(10):3743.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n Kuscu, C., Arslan, S., Singh, R., Thorpe, J. \u0026amp; Adli, M. Genome-wide analysis reveals characteristics of off-target sites bound by the Cas9 endonuclease. Nat Biotechnol 32, 677-683, doi:10.1038/nbt.2916 (2014)\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n Slaymaker, l. M. et al. Rationally engineered Cas9 nucleases with improved specificity. Science 351, 84-88, doi:10.1126/science.aad5227 (2016)\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   ","date":"2021-05-15T22:38:53+08:00","image":"https://pica.zhimg.com/v2-ffc7d038737eaeb8f680cf26b6b45df1_1440w.jpg?source=172ae18b","permalink":"https://deathsprout.gitee.io/p/cas-protein/","title":"Cas Protein"},{"content":"人总有表达自我的需求，从高中到现在大三，这种需求愈发强，宣泄通路倒是逐渐弱。现在不同的领域有各自的论坛、各自的账号，也无非是一个侧写，于我，于他/她，虽然这样说，这个个人博客也只不过是一些想让别人看到的东西罢了。\n我喜欢的东西很多，除本专业外，美术、音乐、哲学、物理、科幻、共产主义等等都很喜欢，自然会的挺杂。就拿美术举例，板绘参加过明日方舟的同人企划，给学校弄过些平面设计，会用blender建模，但我自己现在什么水平我自己清楚，半吊子一个不上不下，比如本来3D建模目的只是渲染出来好看就行，一到给做游戏的同学建模型时就各种破面各种问题，自己谱写的音乐少有灵动多半是狗屎。我懂分散精力在各个领域会导致我学的更浅，我体会得到自己的业余，自己毕竟不能只为了提升3D建模理解去硬啃计算机视觉的内容（或许看不懂还得有前置内容），倒也没有退缩，头脑里的莽劲已经让我将其视为足以坚持一生的爱好。\n在无意中接触到Latex，实在是优美，我在大三上学期决定用latex完全替代word的需求，包括实验报告与笔记，到现在也写八九十个文档了。特别是90页、2500行左右Latex代码的实习报告，花费了我极大的精力，从苦痛慢慢变成享受，精美的完成品PDF给了我很大的成就感，但除我之外估计只有课程老师能去抽出时间草草的浏览一遍，是躺在硬盘里可有可无的东西。\n其他笔记也不外如此，直到一次师兄让我去寻找并下载一组海洋宏基因组数据，我测试完整理了工具和流程，将跑出的PDF发给了师兄，师兄一脸新奇的说：“你写的好像博客哎”。这句话直接促使我产生了搭建个人博客的想法，详细解释一下，生物信息学专业涉及编程或技术细节上的内容，往往需要去阅读相关的手册，有幸不乏喜好惠泽后人的前辈，网上散着一些他们整理好的教程、帖子，实际做之前浏览阅读一些，常常省时省力。看多了，就能发现很多的精美的文章，出现在各式各样的个人博客里，也是因此我才了解了个人博客这一形式。\n我并非没有考虑过使用现有的平台写东西，知乎、CSDN、简书等都挺不错，一个高中朋友弄了个微信公众号也不错，自带平台的搜索权重岂不美哉。但多半是我想折腾，一开始打算使用我的树莓派4B作为服务器挂载这个网站（前段时间还用它挖了一天门罗币，产出和大肠杆菌鞭毛一样，无聊的紧），后来发现我并不需要一个动态的网站，仅仅挂载静态网页就可，鉴于在宿舍总不能一直开着树莓派，转向了借由github的服务挂载网页。便随意买了个网址，解析地址配置好，之后便发现使用github挂载的网页不科学上网不能稳定访问，最后就选择使用gitee了。\n现在这个页面排版是基于HugoTex theme的，原因自然是它的LaTex风格。虽然对它的css和toml等配置文件进行大量改动，增加了一些功能，但它的功能仍是贫弱。现在文章尚少还能接受，推测随着文章数目的增多，我会更改theme，又免不了一阵折腾。\n至于体会，一个长久居住在不同的集体宿舍的人，自己用别人提供的简单方法盖了个简陋的房子。\n","date":"2021-05-12T22:38:53+08:00","permalink":"https://deathsprout.gitee.io/p/%E4%B8%80%E4%BA%9B%E4%B8%8D%E9%87%8D%E8%A6%81%E7%9A%84%E4%BA%8B%E4%B8%BA%E4%BB%80%E4%B9%88%E5%BB%BA%E8%BF%99%E4%B8%AA%E5%8D%9A%E5%AE%A2/","title":"一些不重要的事——为什么建这个博客"}]